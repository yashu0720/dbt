[0m14:52:28.664651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103958d40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045a3a40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045a37d0>]}


============================== 14:52:28.668552 | 810e2130-b6cb-4bb3-a424-e3f6f798115a ==============================
[0m14:52:28.668552 [info ] [MainThread]: Running with dbt=1.8.2
[0m14:52:28.669026 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yash/.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/yash/my_dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:52:28.678790 [info ] [MainThread]: dbt version: 1.8.2
[0m14:52:28.679058 [info ] [MainThread]: python version: 3.12.2
[0m14:52:28.679254 [info ] [MainThread]: python path: /opt/homebrew/opt/python@3.12/bin/python3.12
[0m14:52:28.679430 [info ] [MainThread]: os info: macOS-13.4-arm64-arm-64bit
[0m14:52:28.739820 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:52:28.740219 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:52:28.740452 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:52:29.862609 [info ] [MainThread]: Using profiles dir at /Users/yash/.dbt
[0m14:52:29.863008 [info ] [MainThread]: Using profiles.yml file at /Users/yash/.dbt/profiles.yml
[0m14:52:29.863235 [info ] [MainThread]: Using dbt_project.yml file at /Users/yash/my_dbt/dbt_project.yml
[0m14:52:29.863432 [info ] [MainThread]: adapter type: databricks
[0m14:52:29.863614 [info ] [MainThread]: adapter version: 1.8.1
[0m14:52:29.921206 [info ] [MainThread]: Configuration:
[0m14:52:29.921531 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:52:29.921736 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:52:29.921911 [info ] [MainThread]: Required dependencies:
[0m14:52:29.922137 [debug] [MainThread]: Executing "git --help"
[0m14:52:29.951126 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:52:29.951921 [debug] [MainThread]: STDERR: "b''"
[0m14:52:29.952175 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:52:29.952403 [info ] [MainThread]: Connection:
[0m14:52:29.952637 [info ] [MainThread]:   host: adb-3566505358291970.10.azuredatabricks.net
[0m14:52:29.952819 [info ] [MainThread]:   http_path: /sql/1.0/warehouses/7686f7d22d339e91
[0m14:52:29.952986 [info ] [MainThread]:   catalog: democatalog
[0m14:52:29.953150 [info ] [MainThread]:   schema: demoschema
[0m14:52:29.953645 [info ] [MainThread]: Registered adapter: databricks=1.8.1
[0m14:52:29.958832 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4364957072, session-id=None, name=debug, idle-time=0s, acquire-count=0, language=None, thread-identifier=(81313, 8531893760), compute-name=) - Creating connection
[0m14:52:29.959485 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m14:52:29.959737 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4364957072, session-id=None, name=debug, idle-time=7.152557373046875e-06s, acquire-count=1, language=None, thread-identifier=(81313, 8531893760), compute-name=) - Acquired connection on thread (81313, 8531893760), using default compute resource
[0m14:52:29.960030 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4364957072, session-id=None, name=debug, idle-time=0.0003261566162109375s, acquire-count=1, language=None, thread-identifier=(81313, 8531893760), compute-name=) - Checking idleness
[0m14:52:29.960238 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4364957072, session-id=None, name=debug, idle-time=0.0005450248718261719s, acquire-count=1, language=None, thread-identifier=(81313, 8531893760), compute-name=) - Retrieving connection
[0m14:52:29.960431 [debug] [MainThread]: Using databricks connection "debug"
[0m14:52:29.960651 [debug] [MainThread]: On debug: select 1 as id
[0m14:52:29.960817 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:52:30.256254 [error] [MainThread]: Databricks adapter: Connection(session-id=Unknown) - Exception while trying to create connection: Error during request to server
Error properties: attempt=1/30, bounded-retry-delay=None, elapsed-seconds=0.2814919948577881/900.0, error-message=, http-code=None, method=OpenSession, no-retry-reason=non-retryable error, original-exception=Received 403 - FORBIDDEN. Confirm your authentication credentials., query-id=None, session-id=None
[0m14:52:30.258021 [debug] [MainThread]: Databricks adapter: Exception while trying to execute query
select 1 as id
: Database Error
  Error during request to server
[0m14:52:30.258653 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4364957072, session-id=None, name=debug, idle-time=6.9141387939453125e-06s, acquire-count=0, language=None, thread-identifier=(81313, 8531893760), compute-name=) - Released connection
[0m14:52:30.259081 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m14:52:30.259445 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:52:30.259778 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Runtime Error
  Database Error
    Error during request to server

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m14:52:30.264238 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_wall_clock_time": 1.6469816, "process_user_time": 3.676016, "process_kernel_time": 0.334599, "process_mem_max_rss": "202637312", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m14:52:30.264972 [debug] [MainThread]: Command `dbt debug` failed at 14:52:30.264854 after 1.65 seconds
[0m14:52:30.265438 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:52:30.265708 [debug] [MainThread]: On debug: No close available on handle
[0m14:52:30.266081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045a3260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x159e812e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046657c0>]}
[0m14:52:30.266528 [debug] [MainThread]: Flushing usage events
[0m15:02:15.018147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a9bfe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079e2780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079e2750>]}


============================== 15:02:15.022123 | d250a7a2-18bb-46e4-adc1-bf6161e3f170 ==============================
[0m15:02:15.022123 [info ] [MainThread]: Running with dbt=1.8.2
[0m15:02:15.022613 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/yash/my_dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/yash/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:02:15.032481 [info ] [MainThread]: dbt version: 1.8.2
[0m15:02:15.032753 [info ] [MainThread]: python version: 3.12.2
[0m15:02:15.032970 [info ] [MainThread]: python path: /opt/homebrew/opt/python@3.12/bin/python3.12
[0m15:02:15.033158 [info ] [MainThread]: os info: macOS-13.4-arm64-arm-64bit
[0m15:02:15.089606 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:02:15.089995 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:02:15.090231 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:02:16.221653 [info ] [MainThread]: Using profiles dir at /Users/yash/.dbt
[0m15:02:16.222024 [info ] [MainThread]: Using profiles.yml file at /Users/yash/.dbt/profiles.yml
[0m15:02:16.222241 [info ] [MainThread]: Using dbt_project.yml file at /Users/yash/my_dbt/dbt_project.yml
[0m15:02:16.222431 [info ] [MainThread]: adapter type: databricks
[0m15:02:16.222604 [info ] [MainThread]: adapter version: 1.8.1
[0m15:02:16.281164 [info ] [MainThread]: Configuration:
[0m15:02:16.281508 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m15:02:16.281728 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m15:02:16.281920 [info ] [MainThread]: Required dependencies:
[0m15:02:16.282146 [debug] [MainThread]: Executing "git --help"
[0m15:02:16.312674 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:02:16.313452 [debug] [MainThread]: STDERR: "b''"
[0m15:02:16.313700 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m15:02:16.313934 [info ] [MainThread]: Connection:
[0m15:02:16.314171 [info ] [MainThread]:   host: adb-3566505358291970.10.azuredatabricks.net
[0m15:02:16.314352 [info ] [MainThread]:   http_path: /sql/1.0/warehouses/7686f7d22d339e91
[0m15:02:16.314521 [info ] [MainThread]:   catalog: democatalog
[0m15:02:16.314690 [info ] [MainThread]:   schema: demoschema
[0m15:02:16.315162 [info ] [MainThread]: Registered adapter: databricks=1.8.1
[0m15:02:16.320683 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5033320496, session-id=None, name=debug, idle-time=0s, acquire-count=0, language=None, thread-identifier=(81465, 8531893760), compute-name=) - Creating connection
[0m15:02:16.321633 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m15:02:16.321908 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5033320496, session-id=None, name=debug, idle-time=7.152557373046875e-06s, acquire-count=1, language=None, thread-identifier=(81465, 8531893760), compute-name=) - Acquired connection on thread (81465, 8531893760), using default compute resource
[0m15:02:16.322221 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5033320496, session-id=None, name=debug, idle-time=0.00033402442932128906s, acquire-count=1, language=None, thread-identifier=(81465, 8531893760), compute-name=) - Checking idleness
[0m15:02:16.322443 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5033320496, session-id=None, name=debug, idle-time=0.0005609989166259766s, acquire-count=1, language=None, thread-identifier=(81465, 8531893760), compute-name=) - Retrieving connection
[0m15:02:16.322631 [debug] [MainThread]: Using databricks connection "debug"
[0m15:02:16.322831 [debug] [MainThread]: On debug: select 1 as id
[0m15:02:16.323012 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:02:16.810386 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5033320496, session-id=01ef2764-5634-1487-b4f6-9d2552502582, name=debug, idle-time=1.8835067749023438e-05s, acquire-count=1, language=None, thread-identifier=(81465, 8531893760), compute-name=) - Connection created
[0m15:02:16.811596 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01ef2764-5634-1487-b4f6-9d2552502582, command-id=Unknown) - Created cursor
[0m15:02:18.816051 [debug] [MainThread]: SQL status: OK in 2.490000009536743 seconds
[0m15:02:18.817609 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01ef2764-5634-1487-b4f6-9d2552502582, command-id=01ef2764-5648-1a5e-affc-23413f1bcd02) - Closing cursor
[0m15:02:18.818148 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5033320496, session-id=01ef2764-5634-1487-b4f6-9d2552502582, name=debug, idle-time=4.0531158447265625e-06s, acquire-count=0, language=None, thread-identifier=(81465, 8531893760), compute-name=) - Released connection
[0m15:02:18.818475 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m15:02:18.818773 [info ] [MainThread]: [32mAll checks passed![0m
[0m15:02:18.821461 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 3.8506994, "process_user_time": 3.675372, "process_kernel_time": 0.352368, "process_mem_max_rss": "208699392", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:02:18.822077 [debug] [MainThread]: Command `dbt debug` succeeded at 15:02:18.821978 after 3.85 seconds
[0m15:02:18.822387 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m15:02:18.822612 [debug] [MainThread]: On debug: Close
[0m15:02:18.822839 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef2764-5634-1487-b4f6-9d2552502582) - Closing connection
[0m15:02:19.107677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108582c00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12c026030>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12c17c980>]}
[0m15:02:19.109485 [debug] [MainThread]: Flushing usage events
[0m15:11:14.029345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1144639e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114037a40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e350d0>]}


============================== 15:11:14.033505 | 96a740d9-440f-49fc-a6b0-89f5c18b6bdb ==============================
[0m15:11:14.033505 [info ] [MainThread]: Running with dbt=1.8.2
[0m15:11:14.033997 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/yash/my_dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/yash/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --model models/examples/dbt_model.sql', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:11:14.089619 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:11:14.090116 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:11:14.090392 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:11:15.481058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '96a740d9-440f-49fc-a6b0-89f5c18b6bdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107246f00>]}
[0m15:11:15.518451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '96a740d9-440f-49fc-a6b0-89f5c18b6bdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114076b40>]}
[0m15:11:15.518914 [info ] [MainThread]: Registered adapter: databricks=1.8.1
[0m15:11:15.534455 [debug] [MainThread]: checksum: f0a141b9de567cb7f131613ba2682f40b3a1c6a157f81c6e5435862eff68f109, vars: {}, profile: , target: , version: 1.8.2
[0m15:11:15.535115 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m15:11:15.535417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '96a740d9-440f-49fc-a6b0-89f5c18b6bdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15ffe2fc0>]}
[0m15:11:16.867924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '96a740d9-440f-49fc-a6b0-89f5c18b6bdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x160979f10>]}
[0m15:11:16.934062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '96a740d9-440f-49fc-a6b0-89f5c18b6bdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x160f65e50>]}
[0m15:11:16.934413 [info ] [MainThread]: Found 1 model, 1 source, 586 macros
[0m15:11:16.934646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96a740d9-440f-49fc-a6b0-89f5c18b6bdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x160df0ce0>]}
[0m15:11:16.935325 [warn ] [MainThread]: The selection criterion 'models/examples/dbt_model.sql' does not match any enabled nodes
[0m15:11:16.936101 [info ] [MainThread]: 
[0m15:11:16.936351 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m15:11:16.936674 [debug] [MainThread]: Command end result
[0m15:11:16.960223 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.9787743, "process_user_time": 4.751735, "process_kernel_time": 0.41545, "process_mem_max_rss": "198574080", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:11:16.960642 [debug] [MainThread]: Command `dbt run` succeeded at 15:11:16.960576 after 2.98 seconds
[0m15:11:16.960904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113864d70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1144ad8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x160f1f6b0>]}
[0m15:11:16.961135 [debug] [MainThread]: Flushing usage events
[0m15:11:33.115312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1038c9fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032527b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032527e0>]}


============================== 15:11:33.119110 | a3b3a8dd-390d-426d-988a-2534f4889740 ==============================
[0m15:11:33.119110 [info ] [MainThread]: Running with dbt=1.8.2
[0m15:11:33.119566 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yash/.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/yash/my_dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:11:33.171132 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:11:33.171492 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:11:33.171730 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:11:34.092132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a3b3a8dd-390d-426d-988a-2534f4889740', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103252270>]}
[0m15:11:34.128842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a3b3a8dd-390d-426d-988a-2534f4889740', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1420e5cd0>]}
[0m15:11:34.129280 [info ] [MainThread]: Registered adapter: databricks=1.8.1
[0m15:11:34.144045 [debug] [MainThread]: checksum: f0a141b9de567cb7f131613ba2682f40b3a1c6a157f81c6e5435862eff68f109, vars: {}, profile: , target: , version: 1.8.2
[0m15:11:34.232923 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:11:34.233275 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:11:34.256427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a3b3a8dd-390d-426d-988a-2534f4889740', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10389fda0>]}
[0m15:11:34.372717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a3b3a8dd-390d-426d-988a-2534f4889740', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x142874350>]}
[0m15:11:34.373090 [info ] [MainThread]: Found 1 model, 1 source, 586 macros
[0m15:11:34.373330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a3b3a8dd-390d-426d-988a-2534f4889740', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14220e150>]}
[0m15:11:34.374436 [info ] [MainThread]: 
[0m15:11:34.374885 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Creating connection
[0m15:11:34.375106 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:11:34.375312 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=None, name=master, idle-time=5.0067901611328125e-06s, acquire-count=1, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Acquired connection on thread (81613, 8531893760), using default compute resource
[0m15:11:34.376058 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=None, name=list_democatalog, idle-time=0s, acquire-count=0, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Creating connection
[0m15:11:34.376362 [debug] [ThreadPool]: Acquiring new databricks connection 'list_democatalog'
[0m15:11:34.376592 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=None, name=list_democatalog, idle-time=2.1457672119140625e-06s, acquire-count=1, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Acquired connection on thread (81613, 6185922560), using default compute resource
[0m15:11:34.376832 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=None, name=list_democatalog, idle-time=0.0002522468566894531s, acquire-count=1, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Checking idleness
[0m15:11:34.377036 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=None, name=list_democatalog, idle-time=0.0004570484161376953s, acquire-count=1, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Retrieving connection
[0m15:11:34.377223 [debug] [ThreadPool]: Using databricks connection "list_democatalog"
[0m15:11:34.377399 [debug] [ThreadPool]: On list_democatalog: GetSchemas(database=democatalog, schema=None)
[0m15:11:34.377569 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:11:34.833491 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=list_democatalog, idle-time=1.3113021850585938e-05s, acquire-count=1, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Connection created
[0m15:11:34.834470 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, command-id=Unknown) - Created cursor
[0m15:11:35.562345 [debug] [ThreadPool]: SQL status: OK in 1.1799999475479126 seconds
[0m15:11:35.576461 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, command-id=01ef2765-a2f1-1ae9-9bb6-722988ea82f0) - Closing cursor
[0m15:11:35.576815 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=list_democatalog, idle-time=3.0994415283203125e-06s, acquire-count=0, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Released connection
[0m15:11:35.577630 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=list_democatalog, idle-time=0.0008230209350585938s, acquire-count=0, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Checking idleness
[0m15:11:35.577882 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_democatalog, now list_democatalog_demoschema)
[0m15:11:35.578105 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=list_democatalog_demoschema, idle-time=0.0013031959533691406s, acquire-count=0, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Reusing connection previously named list_democatalog
[0m15:11:35.578313 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=list_democatalog_demoschema, idle-time=0.0015151500701904297s, acquire-count=1, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Acquired connection on thread (81613, 6185922560), using default compute resource
[0m15:11:35.587119 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=list_democatalog_demoschema, idle-time=0.01029515266418457s, acquire-count=1, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Checking idleness
[0m15:11:35.587421 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=list_democatalog_demoschema, idle-time=0.010617256164550781s, acquire-count=1, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Retrieving connection
[0m15:11:35.587654 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=list_democatalog_demoschema, idle-time=0.01085805892944336s, acquire-count=1, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Checking idleness
[0m15:11:35.587868 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=list_democatalog_demoschema, idle-time=0.011073112487792969s, acquire-count=1, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Retrieving connection
[0m15:11:35.588056 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m15:11:35.588220 [debug] [ThreadPool]: Using databricks connection "list_democatalog_demoschema"
[0m15:11:35.588452 [debug] [ThreadPool]: On list_democatalog_demoschema: /* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "connection_name": "list_democatalog_demoschema"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `democatalog`.`information_schema`.`tables`
    where table_schema = 'demoschema'
    
  
[0m15:11:35.588683 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, command-id=Unknown) - Created cursor
[0m15:11:36.997521 [debug] [ThreadPool]: SQL status: OK in 1.409999966621399 seconds
[0m15:11:37.000823 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, command-id=01ef2765-a358-1ab9-a822-abf4eb7a44a9) - Closing cursor
[0m15:11:37.001550 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=list_democatalog_demoschema, idle-time=4.0531158447265625e-06s, acquire-count=0, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Released connection
[0m15:11:37.002484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a3b3a8dd-390d-426d-988a-2534f4889740', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1427e7620>]}
[0m15:11:37.003028 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=None, name=master, idle-time=2.62768292427063s, acquire-count=1, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Checking idleness
[0m15:11:37.003435 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=None, name=master, idle-time=2.6280949115753174s, acquire-count=1, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Retrieving connection
[0m15:11:37.003749 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=None, name=master, idle-time=2.628434896469116s, acquire-count=1, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Checking idleness
[0m15:11:37.004035 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=None, name=master, idle-time=2.628722906112671s, acquire-count=1, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Retrieving connection
[0m15:11:37.004291 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m15:11:37.004532 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m15:11:37.004784 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=None, name=master, idle-time=1.9073486328125e-06s, acquire-count=0, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Released connection
[0m15:11:37.005154 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:11:37.005431 [info ] [MainThread]: 
[0m15:11:37.015228 [debug] [Thread-1 (]: Began running node model.my_dbt.dbt_model
[0m15:11:37.015656 [info ] [Thread-1 (]: 1 of 1 START sql view model demoschema.dbt_model ............................... [RUN]
[0m15:11:37.016072 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=list_democatalog_demoschema, idle-time=0.014522075653076172s, acquire-count=0, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Checking idleness
[0m15:11:37.016304 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_democatalog_demoschema, now model.my_dbt.dbt_model)
[0m15:11:37.016581 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=model.my_dbt.dbt_model, idle-time=0.01503896713256836s, acquire-count=0, language=None, thread-identifier=(81613, 6185922560), compute-name=) - Reusing connection previously named list_democatalog_demoschema
[0m15:11:37.016871 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=model.my_dbt.dbt_model, idle-time=0.01532888412475586s, acquire-count=1, language=sql, thread-identifier=(81613, 6185922560), compute-name=) - Acquired connection on thread (81613, 6185922560), using default compute resource for model '`democatalog`.`demoschema`.`dbt_model`'
[0m15:11:37.017137 [debug] [Thread-1 (]: Began compiling node model.my_dbt.dbt_model
[0m15:11:37.022930 [debug] [Thread-1 (]: Writing injected SQL for node "model.my_dbt.dbt_model"
[0m15:11:37.023625 [debug] [Thread-1 (]: Began executing node model.my_dbt.dbt_model
[0m15:11:37.047827 [debug] [Thread-1 (]: Writing runtime sql for node "model.my_dbt.dbt_model"
[0m15:11:37.049858 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=model.my_dbt.dbt_model, idle-time=0.048300981521606445s, acquire-count=1, language=sql, thread-identifier=(81613, 6185922560), compute-name=) - Checking idleness
[0m15:11:37.050173 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=model.my_dbt.dbt_model, idle-time=0.04864192008972168s, acquire-count=1, language=sql, thread-identifier=(81613, 6185922560), compute-name=) - Retrieving connection
[0m15:11:37.050371 [debug] [Thread-1 (]: Using databricks connection "model.my_dbt.dbt_model"
[0m15:11:37.050626 [debug] [Thread-1 (]: On model.my_dbt.dbt_model: /* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "node_id": "model.my_dbt.dbt_model"} */
create or replace view `democatalog`.`demoschema`.`dbt_model`
  
  
  
  as
    with source_data as (
    select * from `democatalog`.`billing`.`list_prices`
)

select
    account_id,
    price_end_time,
from source_data
where price_end_time= null

[0m15:11:37.050884 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, command-id=Unknown) - Created cursor
[0m15:11:37.845433 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, command-id=Unknown) - Closing cursor
[0m15:11:37.846880 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "node_id": "model.my_dbt.dbt_model"} */
create or replace view `democatalog`.`demoschema`.`dbt_model`
  
  
  
  as
    with source_data as (
    select * from `democatalog`.`billing`.`list_prices`
)

select
    account_id,
    price_end_time,
from source_data
where price_end_time= null

: [TABLE_OR_VIEW_NOT_FOUND] The table or view `democatalog`.`billing`.`list_prices` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 8 pos 18
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `democatalog`.`billing`.`list_prices` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 8 pos 18
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:718)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:45)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:103)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:560)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:429)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:427)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:481)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:464)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:190)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:185)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `democatalog`.`billing`.`list_prices` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 8 pos 18
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:688)
	... 36 more
, operation-id=01ef2765-a442-1f74-89cb-5470b9b54bb5
[0m15:11:37.848185 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=model.my_dbt.dbt_model, idle-time=6.198883056640625e-06s, acquire-count=0, language=sql, thread-identifier=(81613, 6185922560), compute-name=) - Released connection
[0m15:11:37.861234 [debug] [Thread-1 (]: Runtime Error in model dbt_model (models/example/dbt_model.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `democatalog`.`billing`.`list_prices` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 8 pos 18
[0m15:11:37.861777 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5411132368, session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2, name=model.my_dbt.dbt_model, idle-time=4.0531158447265625e-06s, acquire-count=0, language=sql, thread-identifier=(81613, 6185922560), compute-name=) - Released connection
[0m15:11:37.863227 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3b3a8dd-390d-426d-988a-2534f4889740', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x142bdaa80>]}
[0m15:11:37.863857 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model demoschema.dbt_model ...................... [[31mERROR[0m in 0.85s]
[0m15:11:37.864440 [debug] [Thread-1 (]: Finished running node model.my_dbt.dbt_model
[0m15:11:37.866124 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=None, name=master, idle-time=0.861321210861206s, acquire-count=0, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Checking idleness
[0m15:11:37.866424 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=None, name=master, idle-time=0.8616440296173096s, acquire-count=0, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Reusing connection previously named master
[0m15:11:37.866670 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=None, name=master, idle-time=0.8618888854980469s, acquire-count=1, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Acquired connection on thread (81613, 8531893760), using default compute resource
[0m15:11:37.866920 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=None, name=master, idle-time=0.8621470928192139s, acquire-count=1, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Checking idleness
[0m15:11:37.867146 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=None, name=master, idle-time=0.8623740673065186s, acquire-count=1, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Retrieving connection
[0m15:11:37.867352 [debug] [MainThread]: On master: ROLLBACK
[0m15:11:37.867544 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:11:38.059193 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=01ef2765-a4c5-1065-a1a8-4eed460d73eb, name=master, idle-time=1.0967254638671875e-05s, acquire-count=1, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Connection created
[0m15:11:38.060106 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:11:38.060642 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=01ef2765-a4c5-1065-a1a8-4eed460d73eb, name=master, idle-time=0.0016908645629882812s, acquire-count=1, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Checking idleness
[0m15:11:38.061060 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=01ef2765-a4c5-1065-a1a8-4eed460d73eb, name=master, idle-time=0.002107858657836914s, acquire-count=1, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Retrieving connection
[0m15:11:38.061472 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m15:11:38.061864 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m15:11:38.062292 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5414396528, session-id=01ef2765-a4c5-1065-a1a8-4eed460d73eb, name=master, idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(81613, 8531893760), compute-name=) - Released connection
[0m15:11:38.062922 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:11:38.063312 [debug] [MainThread]: On master: ROLLBACK
[0m15:11:38.063670 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:11:38.064019 [debug] [MainThread]: On master: Close
[0m15:11:38.064405 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef2765-a4c5-1065-a1a8-4eed460d73eb) - Closing connection
[0m15:11:38.196822 [debug] [MainThread]: Connection 'model.my_dbt.dbt_model' was properly closed.
[0m15:11:38.198011 [debug] [MainThread]: On model.my_dbt.dbt_model: ROLLBACK
[0m15:11:38.198842 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:11:38.199545 [debug] [MainThread]: On model.my_dbt.dbt_model: Close
[0m15:11:38.200293 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef2765-a2d7-1ed6-be30-7b2589bf66b2) - Closing connection
[0m15:11:38.285208 [info ] [MainThread]: 
[0m15:11:38.285996 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 3.91 seconds (3.91s).
[0m15:11:38.287039 [debug] [MainThread]: Command end result
[0m15:11:38.318621 [info ] [MainThread]: 
[0m15:11:38.319026 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:11:38.319249 [info ] [MainThread]: 
[0m15:11:38.319532 [error] [MainThread]:   Runtime Error in model dbt_model (models/example/dbt_model.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `democatalog`.`billing`.`list_prices` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 8 pos 18
[0m15:11:38.319747 [info ] [MainThread]: 
[0m15:11:38.319949 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:11:38.322039 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 5.251662, "process_user_time": 3.684751, "process_kernel_time": 0.507394, "process_mem_max_rss": "218349568", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:11:38.322529 [debug] [MainThread]: Command `dbt run` failed at 15:11:38.322451 after 5.25 seconds
[0m15:11:38.322843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103d0f200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102cd3470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1421f9a30>]}
[0m15:11:38.323108 [debug] [MainThread]: Flushing usage events
[0m15:15:18.238004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1035fbfe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c63ec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c63c50>]}


============================== 15:15:18.242077 | dff41830-b88f-4179-9440-a2bb14746425 ==============================
[0m15:15:18.242077 [info ] [MainThread]: Running with dbt=1.8.2
[0m15:15:18.242522 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yash/.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/yash/my_dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:15:18.300838 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:15:18.301302 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:15:18.301541 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:15:19.314931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dff41830-b88f-4179-9440-a2bb14746425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103b72f30>]}
[0m15:15:19.352378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dff41830-b88f-4179-9440-a2bb14746425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c40440>]}
[0m15:15:19.352821 [info ] [MainThread]: Registered adapter: databricks=1.8.1
[0m15:15:19.368051 [debug] [MainThread]: checksum: f0a141b9de567cb7f131613ba2682f40b3a1c6a157f81c6e5435862eff68f109, vars: {}, profile: , target: , version: 1.8.2
[0m15:15:19.428999 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m15:15:19.429493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'dff41830-b88f-4179-9440-a2bb14746425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x143d83d10>]}
[0m15:15:20.579846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dff41830-b88f-4179-9440-a2bb14746425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x143d0aea0>]}
[0m15:15:20.644879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dff41830-b88f-4179-9440-a2bb14746425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x144d10c80>]}
[0m15:15:20.645226 [info ] [MainThread]: Found 1 model, 1 source, 586 macros
[0m15:15:20.645466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dff41830-b88f-4179-9440-a2bb14746425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x143fb3140>]}
[0m15:15:20.646577 [info ] [MainThread]: 
[0m15:15:20.647003 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Creating connection
[0m15:15:20.647216 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:15:20.647426 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=None, name=master, idle-time=4.76837158203125e-06s, acquire-count=1, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Acquired connection on thread (81682, 8531893760), using default compute resource
[0m15:15:20.648007 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=None, name=list_system, idle-time=0s, acquire-count=0, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Creating connection
[0m15:15:20.648317 [debug] [ThreadPool]: Acquiring new databricks connection 'list_system'
[0m15:15:20.648544 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=None, name=list_system, idle-time=2.86102294921875e-06s, acquire-count=1, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Acquired connection on thread (81682, 6193278976), using default compute resource
[0m15:15:20.648919 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=None, name=list_system, idle-time=0.0003807544708251953s, acquire-count=1, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Checking idleness
[0m15:15:20.649135 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=None, name=list_system, idle-time=0.0006008148193359375s, acquire-count=1, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Retrieving connection
[0m15:15:20.649312 [debug] [ThreadPool]: Using databricks connection "list_system"
[0m15:15:20.649486 [debug] [ThreadPool]: On list_system: GetSchemas(database=system, schema=None)
[0m15:15:20.649654 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:15:20.968200 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=list_system, idle-time=1.5974044799804688e-05s, acquire-count=1, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Connection created
[0m15:15:20.969217 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2766-29a4-1606-b725-008bff36bf00, command-id=Unknown) - Created cursor
[0m15:15:21.993540 [debug] [ThreadPool]: SQL status: OK in 1.340000033378601 seconds
[0m15:15:22.008116 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2766-29a4-1606-b725-008bff36bf00, command-id=01ef2766-29bb-1fdf-9435-b4ca67b28e69) - Closing cursor
[0m15:15:22.008525 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=list_system, idle-time=3.814697265625e-06s, acquire-count=0, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Released connection
[0m15:15:22.009503 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=list_system, idle-time=0.000988006591796875s, acquire-count=0, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Checking idleness
[0m15:15:22.009770 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_system, now list_system_billing)
[0m15:15:22.009999 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=list_system_billing, idle-time=0.0014929771423339844s, acquire-count=0, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Reusing connection previously named list_system
[0m15:15:22.010210 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=list_system_billing, idle-time=0.0017070770263671875s, acquire-count=1, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Acquired connection on thread (81682, 6193278976), using default compute resource
[0m15:15:22.017959 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=list_system_billing, idle-time=0.009434938430786133s, acquire-count=1, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Checking idleness
[0m15:15:22.018233 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=list_system_billing, idle-time=0.009727001190185547s, acquire-count=1, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Retrieving connection
[0m15:15:22.018469 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=list_system_billing, idle-time=0.009970903396606445s, acquire-count=1, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Checking idleness
[0m15:15:22.018672 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=list_system_billing, idle-time=0.010175943374633789s, acquire-count=1, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Retrieving connection
[0m15:15:22.018850 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m15:15:22.019009 [debug] [ThreadPool]: Using databricks connection "list_system_billing"
[0m15:15:22.019217 [debug] [ThreadPool]: On list_system_billing: /* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "connection_name": "list_system_billing"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_schema = 'billing'
    
  
[0m15:15:22.019439 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2766-29a4-1606-b725-008bff36bf00, command-id=Unknown) - Created cursor
[0m15:15:22.566556 [debug] [ThreadPool]: SQL status: OK in 0.550000011920929 seconds
[0m15:15:22.570140 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2766-29a4-1606-b725-008bff36bf00, command-id=01ef2766-2a52-1789-b836-08731b8c8c15) - Closing cursor
[0m15:15:22.570866 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=list_system_billing, idle-time=3.0994415283203125e-06s, acquire-count=0, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Released connection
[0m15:15:22.571764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dff41830-b88f-4179-9440-a2bb14746425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049af800>]}
[0m15:15:22.572192 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=None, name=master, idle-time=1.9247548580169678s, acquire-count=1, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Checking idleness
[0m15:15:22.572475 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=None, name=master, idle-time=1.925048828125s, acquire-count=1, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Retrieving connection
[0m15:15:22.572744 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=None, name=master, idle-time=1.9253208637237549s, acquire-count=1, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Checking idleness
[0m15:15:22.573008 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=None, name=master, idle-time=1.9255859851837158s, acquire-count=1, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Retrieving connection
[0m15:15:22.573241 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m15:15:22.573462 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m15:15:22.573714 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=None, name=master, idle-time=1.9073486328125e-06s, acquire-count=0, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Released connection
[0m15:15:22.574095 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:15:22.574386 [info ] [MainThread]: 
[0m15:15:22.576694 [debug] [Thread-1 (]: Began running node model.my_dbt.dbt_model
[0m15:15:22.577152 [info ] [Thread-1 (]: 1 of 1 START sql view model billing.dbt_model .................................. [RUN]
[0m15:15:22.577555 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=list_system_billing, idle-time=0.006686210632324219s, acquire-count=0, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Checking idleness
[0m15:15:22.577791 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_system_billing, now model.my_dbt.dbt_model)
[0m15:15:22.578056 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=model.my_dbt.dbt_model, idle-time=0.007196187973022461s, acquire-count=0, language=None, thread-identifier=(81682, 6193278976), compute-name=) - Reusing connection previously named list_system_billing
[0m15:15:22.578331 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=model.my_dbt.dbt_model, idle-time=0.00746607780456543s, acquire-count=1, language=sql, thread-identifier=(81682, 6193278976), compute-name=) - Acquired connection on thread (81682, 6193278976), using default compute resource for model '`system`.`billing`.`dbt_model`'
[0m15:15:22.578590 [debug] [Thread-1 (]: Began compiling node model.my_dbt.dbt_model
[0m15:15:22.585077 [debug] [Thread-1 (]: Writing injected SQL for node "model.my_dbt.dbt_model"
[0m15:15:22.585675 [debug] [Thread-1 (]: Began executing node model.my_dbt.dbt_model
[0m15:15:22.607524 [debug] [Thread-1 (]: Writing runtime sql for node "model.my_dbt.dbt_model"
[0m15:15:22.608063 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=model.my_dbt.dbt_model, idle-time=0.037203311920166016s, acquire-count=1, language=sql, thread-identifier=(81682, 6193278976), compute-name=) - Checking idleness
[0m15:15:22.608332 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=model.my_dbt.dbt_model, idle-time=0.03748607635498047s, acquire-count=1, language=sql, thread-identifier=(81682, 6193278976), compute-name=) - Retrieving connection
[0m15:15:22.608515 [debug] [Thread-1 (]: Using databricks connection "model.my_dbt.dbt_model"
[0m15:15:22.608759 [debug] [Thread-1 (]: On model.my_dbt.dbt_model: /* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "node_id": "model.my_dbt.dbt_model"} */
create or replace view `system`.`billing`.`dbt_model`
  
  
  
  as
    with source_data as (
    select * from `system`.`billing`.`list_prices`
)

select
    account_id,
    price_end_time,
from source_data
where price_end_time= null

[0m15:15:22.609029 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01ef2766-29a4-1606-b725-008bff36bf00, command-id=Unknown) - Created cursor
[0m15:15:23.281398 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01ef2766-29a4-1606-b725-008bff36bf00, command-id=Unknown) - Closing cursor
[0m15:15:23.282680 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "node_id": "model.my_dbt.dbt_model"} */
create or replace view `system`.`billing`.`dbt_model`
  
  
  
  as
    with source_data as (
    select * from `system`.`billing`.`list_prices`
)

select
    account_id,
    price_end_time,
from source_data
where price_end_time= null

: [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column, variable, or function parameter with name `price_end_time` cannot be resolved.  SQLSTATE: 42703; line 15 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column, variable, or function parameter with name `price_end_time` cannot be resolved.  SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:718)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:45)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:103)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:560)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:429)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:427)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:481)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:464)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:190)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:185)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column, variable, or function parameter with name `price_end_time` cannot be resolved.  SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:688)
	... 36 more
, operation-id=01ef2766-2aaf-1fc9-bcf1-f8d7c6e3db50
[0m15:15:23.283798 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=model.my_dbt.dbt_model, idle-time=7.152557373046875e-06s, acquire-count=0, language=sql, thread-identifier=(81682, 6193278976), compute-name=) - Released connection
[0m15:15:23.296370 [debug] [Thread-1 (]: Runtime Error in model dbt_model (models/example/dbt_model.sql)
  [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column, variable, or function parameter with name `price_end_time` cannot be resolved.  SQLSTATE: 42703; line 15 pos 6
[0m15:15:23.296897 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5449526608, session-id=01ef2766-29a4-1606-b725-008bff36bf00, name=model.my_dbt.dbt_model, idle-time=3.814697265625e-06s, acquire-count=0, language=sql, thread-identifier=(81682, 6193278976), compute-name=) - Released connection
[0m15:15:23.298403 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dff41830-b88f-4179-9440-a2bb14746425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10428c230>]}
[0m15:15:23.299056 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model billing.dbt_model ......................... [[31mERROR[0m in 0.72s]
[0m15:15:23.299618 [debug] [Thread-1 (]: Finished running node model.my_dbt.dbt_model
[0m15:15:23.301323 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=None, name=master, idle-time=0.7275629043579102s, acquire-count=0, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Checking idleness
[0m15:15:23.301687 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=None, name=master, idle-time=0.7279698848724365s, acquire-count=0, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Reusing connection previously named master
[0m15:15:23.301950 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=None, name=master, idle-time=0.7282381057739258s, acquire-count=1, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Acquired connection on thread (81682, 8531893760), using default compute resource
[0m15:15:23.302204 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=None, name=master, idle-time=0.7284998893737793s, acquire-count=1, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Checking idleness
[0m15:15:23.302440 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=None, name=master, idle-time=0.7287380695343018s, acquire-count=1, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Retrieving connection
[0m15:15:23.302656 [debug] [MainThread]: On master: ROLLBACK
[0m15:15:23.302855 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:15:23.588296 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=01ef2766-2b30-1c02-8db9-2291a00a3f9b, name=master, idle-time=1.621246337890625e-05s, acquire-count=1, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Connection created
[0m15:15:23.589455 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:15:23.589984 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=01ef2766-2b30-1c02-8db9-2291a00a3f9b, name=master, idle-time=0.0020961761474609375s, acquire-count=1, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Checking idleness
[0m15:15:23.590380 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=01ef2766-2b30-1c02-8db9-2291a00a3f9b, name=master, idle-time=0.0025060176849365234s, acquire-count=1, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Retrieving connection
[0m15:15:23.590745 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m15:15:23.591388 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m15:15:23.591889 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5430525152, session-id=01ef2766-2b30-1c02-8db9-2291a00a3f9b, name=master, idle-time=4.0531158447265625e-06s, acquire-count=0, language=None, thread-identifier=(81682, 8531893760), compute-name=) - Released connection
[0m15:15:23.592459 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:15:23.592815 [debug] [MainThread]: On master: ROLLBACK
[0m15:15:23.593106 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:15:23.593377 [debug] [MainThread]: On master: Close
[0m15:15:23.593670 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef2766-2b30-1c02-8db9-2291a00a3f9b) - Closing connection
[0m15:15:23.684596 [debug] [MainThread]: Connection 'model.my_dbt.dbt_model' was properly closed.
[0m15:15:23.685646 [debug] [MainThread]: On model.my_dbt.dbt_model: ROLLBACK
[0m15:15:23.686453 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:15:23.687139 [debug] [MainThread]: On model.my_dbt.dbt_model: Close
[0m15:15:23.687868 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef2766-29a4-1606-b725-008bff36bf00) - Closing connection
[0m15:15:23.815154 [info ] [MainThread]: 
[0m15:15:23.816143 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 3.17 seconds (3.17s).
[0m15:15:23.817082 [debug] [MainThread]: Command end result
[0m15:15:23.846576 [info ] [MainThread]: 
[0m15:15:23.846930 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:15:23.847138 [info ] [MainThread]: 
[0m15:15:23.847412 [error] [MainThread]:   Runtime Error in model dbt_model (models/example/dbt_model.sql)
  [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column, variable, or function parameter with name `price_end_time` cannot be resolved.  SQLSTATE: 42703; line 15 pos 6
[0m15:15:23.847625 [info ] [MainThread]: 
[0m15:15:23.847824 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:15:23.849847 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 5.6591353, "process_user_time": 4.967551, "process_kernel_time": 0.328184, "process_mem_max_rss": "215760896", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:15:23.850261 [debug] [MainThread]: Command `dbt run` failed at 15:15:23.850197 after 5.66 seconds
[0m15:15:23.850553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c1b500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10471de80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c63c50>]}
[0m15:15:23.850800 [debug] [MainThread]: Flushing usage events
[0m15:17:12.446561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104316e70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10354a7e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10354a7b0>]}


============================== 15:17:12.450711 | 4e091f4f-bcec-4605-8e82-fc4377113c4d ==============================
[0m15:17:12.450711 [info ] [MainThread]: Running with dbt=1.8.2
[0m15:17:12.451171 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/yash/.dbt', 'log_path': '/Users/yash/my_dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:17:12.506474 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:17:12.506869 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:17:12.507107 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:17:13.516578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4e091f4f-bcec-4605-8e82-fc4377113c4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10354a240>]}
[0m15:17:13.560059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4e091f4f-bcec-4605-8e82-fc4377113c4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103a6ff50>]}
[0m15:17:13.560695 [info ] [MainThread]: Registered adapter: databricks=1.8.1
[0m15:17:13.577199 [debug] [MainThread]: checksum: f0a141b9de567cb7f131613ba2682f40b3a1c6a157f81c6e5435862eff68f109, vars: {}, profile: , target: , version: 1.8.2
[0m15:17:13.666385 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:17:13.666892 [debug] [MainThread]: Partial parsing: updated file: my_dbt://models/example/dbt_model.sql
[0m15:17:13.874626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4e091f4f-bcec-4605-8e82-fc4377113c4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127d92d20>]}
[0m15:17:13.939842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4e091f4f-bcec-4605-8e82-fc4377113c4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x132d1a2d0>]}
[0m15:17:13.940187 [info ] [MainThread]: Found 1 model, 1 source, 586 macros
[0m15:17:13.940430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e091f4f-bcec-4605-8e82-fc4377113c4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1278bad80>]}
[0m15:17:13.941553 [info ] [MainThread]: 
[0m15:17:13.941970 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Creating connection
[0m15:17:13.942187 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:17:13.942394 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=None, name=master, idle-time=1.9073486328125e-06s, acquire-count=1, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Acquired connection on thread (81697, 8531893760), using default compute resource
[0m15:17:13.942984 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=None, name=list_system, idle-time=0s, acquire-count=0, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Creating connection
[0m15:17:13.943286 [debug] [ThreadPool]: Acquiring new databricks connection 'list_system'
[0m15:17:13.943518 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=None, name=list_system, idle-time=2.1457672119140625e-06s, acquire-count=1, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Acquired connection on thread (81697, 6199980032), using default compute resource
[0m15:17:13.943904 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=None, name=list_system, idle-time=0.000392913818359375s, acquire-count=1, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Checking idleness
[0m15:17:13.944128 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=None, name=list_system, idle-time=0.0006220340728759766s, acquire-count=1, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Retrieving connection
[0m15:17:13.944314 [debug] [ThreadPool]: Using databricks connection "list_system"
[0m15:17:13.944498 [debug] [ThreadPool]: On list_system: GetSchemas(database=system, schema=None)
[0m15:17:13.944668 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:17:14.292093 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=list_system, idle-time=1.0013580322265625e-05s, acquire-count=1, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Connection created
[0m15:17:14.293397 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, command-id=Unknown) - Created cursor
[0m15:17:15.077308 [debug] [ThreadPool]: SQL status: OK in 1.1299999952316284 seconds
[0m15:17:15.080734 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, command-id=01ef2766-6d41-10a0-9ae6-391b6ad435a1) - Closing cursor
[0m15:17:15.081203 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=list_system, idle-time=4.291534423828125e-06s, acquire-count=0, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Released connection
[0m15:17:15.082296 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=list_system, idle-time=0.0010952949523925781s, acquire-count=0, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Checking idleness
[0m15:17:15.082619 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_system, now list_system_billing)
[0m15:17:15.082894 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=list_system_billing, idle-time=0.0017092227935791016s, acquire-count=0, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Reusing connection previously named list_system
[0m15:17:15.083139 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=list_system_billing, idle-time=0.0019631385803222656s, acquire-count=1, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Acquired connection on thread (81697, 6199980032), using default compute resource
[0m15:17:15.091024 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=list_system_billing, idle-time=0.00982809066772461s, acquire-count=1, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Checking idleness
[0m15:17:15.091311 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=list_system_billing, idle-time=0.010133028030395508s, acquire-count=1, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Retrieving connection
[0m15:17:15.091576 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=list_system_billing, idle-time=0.010406255722045898s, acquire-count=1, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Checking idleness
[0m15:17:15.091787 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=list_system_billing, idle-time=0.010621070861816406s, acquire-count=1, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Retrieving connection
[0m15:17:15.091968 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m15:17:15.092134 [debug] [ThreadPool]: Using databricks connection "list_system_billing"
[0m15:17:15.092349 [debug] [ThreadPool]: On list_system_billing: /* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "connection_name": "list_system_billing"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_schema = 'billing'
    
  
[0m15:17:15.092577 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, command-id=Unknown) - Created cursor
[0m15:17:15.611561 [debug] [ThreadPool]: SQL status: OK in 0.5199999809265137 seconds
[0m15:17:15.617545 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, command-id=01ef2766-6db9-156f-aa12-015a39a02745) - Closing cursor
[0m15:17:15.618668 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=list_system_billing, idle-time=1.0728836059570312e-05s, acquire-count=0, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Released connection
[0m15:17:15.620113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e091f4f-bcec-4605-8e82-fc4377113c4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104317dd0>]}
[0m15:17:15.620701 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=None, name=master, idle-time=1.6782608032226562s, acquire-count=1, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Checking idleness
[0m15:17:15.621065 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=None, name=master, idle-time=1.6786448955535889s, acquire-count=1, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Retrieving connection
[0m15:17:15.621418 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=None, name=master, idle-time=1.6790049076080322s, acquire-count=1, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Checking idleness
[0m15:17:15.621749 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=None, name=master, idle-time=1.6793389320373535s, acquire-count=1, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Retrieving connection
[0m15:17:15.622059 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m15:17:15.622339 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m15:17:15.622657 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=None, name=master, idle-time=3.0994415283203125e-06s, acquire-count=0, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Released connection
[0m15:17:15.623087 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:17:15.623435 [info ] [MainThread]: 
[0m15:17:15.626391 [debug] [Thread-1 (]: Began running node model.my_dbt.dbt_model
[0m15:17:15.626895 [info ] [Thread-1 (]: 1 of 1 START sql view model billing.dbt_model .................................. [RUN]
[0m15:17:15.627399 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=list_system_billing, idle-time=0.008716821670532227s, acquire-count=0, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Checking idleness
[0m15:17:15.627691 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_system_billing, now model.my_dbt.dbt_model)
[0m15:17:15.628022 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=model.my_dbt.dbt_model, idle-time=0.009351968765258789s, acquire-count=0, language=None, thread-identifier=(81697, 6199980032), compute-name=) - Reusing connection previously named list_system_billing
[0m15:17:15.628367 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=model.my_dbt.dbt_model, idle-time=0.009699821472167969s, acquire-count=1, language=sql, thread-identifier=(81697, 6199980032), compute-name=) - Acquired connection on thread (81697, 6199980032), using default compute resource for model '`system`.`billing`.`dbt_model`'
[0m15:17:15.628671 [debug] [Thread-1 (]: Began compiling node model.my_dbt.dbt_model
[0m15:17:15.636014 [debug] [Thread-1 (]: Writing injected SQL for node "model.my_dbt.dbt_model"
[0m15:17:15.636720 [debug] [Thread-1 (]: Began executing node model.my_dbt.dbt_model
[0m15:17:15.658651 [debug] [Thread-1 (]: Writing runtime sql for node "model.my_dbt.dbt_model"
[0m15:17:15.659201 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=model.my_dbt.dbt_model, idle-time=0.040547847747802734s, acquire-count=1, language=sql, thread-identifier=(81697, 6199980032), compute-name=) - Checking idleness
[0m15:17:15.659481 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=model.my_dbt.dbt_model, idle-time=0.040846824645996094s, acquire-count=1, language=sql, thread-identifier=(81697, 6199980032), compute-name=) - Retrieving connection
[0m15:17:15.659668 [debug] [Thread-1 (]: Using databricks connection "model.my_dbt.dbt_model"
[0m15:17:15.659949 [debug] [Thread-1 (]: On model.my_dbt.dbt_model: /* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "node_id": "model.my_dbt.dbt_model"} */
create or replace view `system`.`billing`.`dbt_model`
  
  
  
  as
    with source_data as (
    select * from `system`.`billing`.`list_prices`
)

select
    account_id,
    cloud
from source_data
where cloud='AZURE'

[0m15:17:15.660219 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, command-id=Unknown) - Created cursor
[0m15:17:17.873083 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, command-id=Unknown) - Closing cursor
[0m15:17:17.875235 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "node_id": "model.my_dbt.dbt_model"} */
create or replace view `system`.`billing`.`dbt_model`
  
  
  
  as
    with source_data as (
    select * from `system`.`billing`.`list_prices`
)

select
    account_id,
    cloud
from source_data
where cloud='AZURE'

: PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNAUTHORIZED_ACCESS] com.databricks.sql.managedcatalog.acl.UnauthorizedAccessException: PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:718)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:45)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:103)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:560)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:429)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:427)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:481)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:464)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:190)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:185)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: com.databricks.sql.managedcatalog.acl.UnauthorizedAccessException: PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
	at com.databricks.managedcatalog.UCReliableHttpClient.reliablyAndTranslateExceptions(UCReliableHttpClient.scala:87)
	at com.databricks.managedcatalog.UCReliableHttpClient.postJson(UCReliableHttpClient.scala:103)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.createTableInternal(ManagedCatalogClientImpl.scala:889)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$createTable$1(ManagedCatalogClientImpl.scala:998)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapException$2(ManagedCatalogClientImpl.scala:4920)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapException$1(ManagedCatalogClientImpl.scala:4919)
	at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException(ErrorDetailsHandler.scala:26)
	at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException$(ErrorDetailsHandler.scala:24)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:163)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:4916)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.createTable(ManagedCatalogClientImpl.scala:991)
	at com.databricks.sql.managedcatalog.PermissionEnforcingManagedCatalog.createManagedOrExternalTable(PermissionEnforcingManagedCatalog.scala:87)
	at com.databricks.sql.managedcatalog.PermissionEnforcingManagedCatalog.createTable(PermissionEnforcingManagedCatalog.scala:287)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$createTable$1(ProfiledManagedCatalog.scala:181)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:717)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:62)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:61)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.createTable(ProfiledManagedCatalog.scala:181)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.createTableInternal(ManagedCatalogSessionCatalog.scala:789)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.createTable(ManagedCatalogSessionCatalog.scala:725)
	at com.databricks.sql.DatabricksSessionCatalog.createTable(DatabricksSessionCatalog.scala:225)
	at org.apache.spark.sql.execution.command.CreateViewCommand.run(views.scala:250)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:84)
	at org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)
	at org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:84)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:81)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:80)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:94)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$5(QueryExecution.scala:375)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$4(QueryExecution.scala:375)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:166)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:375)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$9(SQLExecution.scala:386)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:669)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:275)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1175)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:162)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:606)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:371)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1098)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:367)
	at org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:318)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:364)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:340)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:477)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:83)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:477)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:40)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:343)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:339)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:453)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:340)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:400)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:340)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:277)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:274)
	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:310)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.getOrCreateDF(SparkExecuteStatementOperation.scala:500)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.analyzeQuery(SparkExecuteStatementOperation.scala:523)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$5(SparkExecuteStatementOperation.scala:598)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:531)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:598)
	... 36 more
, operation-id=01ef2766-6e11-1512-b061-c4986d2a2809
[0m15:17:17.877103 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=model.my_dbt.dbt_model, idle-time=1.3113021850585938e-05s, acquire-count=0, language=sql, thread-identifier=(81697, 6199980032), compute-name=) - Released connection
[0m15:17:17.891647 [debug] [Thread-1 (]: Runtime Error in model dbt_model (models/example/dbt_model.sql)
  PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
[0m15:17:17.892166 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5147568336, session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2, name=model.my_dbt.dbt_model, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(81697, 6199980032), compute-name=) - Released connection
[0m15:17:17.893711 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e091f4f-bcec-4605-8e82-fc4377113c4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127693740>]}
[0m15:17:17.894390 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model billing.dbt_model ......................... [[31mERROR[0m in 2.27s]
[0m15:17:17.894986 [debug] [Thread-1 (]: Finished running node model.my_dbt.dbt_model
[0m15:17:17.896692 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=None, name=master, idle-time=2.2740159034729004s, acquire-count=0, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Checking idleness
[0m15:17:17.897067 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=None, name=master, idle-time=2.2744131088256836s, acquire-count=0, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Reusing connection previously named master
[0m15:17:17.897336 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=None, name=master, idle-time=2.2746939659118652s, acquire-count=1, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Acquired connection on thread (81697, 8531893760), using default compute resource
[0m15:17:17.897604 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=None, name=master, idle-time=2.274970054626465s, acquire-count=1, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Checking idleness
[0m15:17:17.897836 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=None, name=master, idle-time=2.275202989578247s, acquire-count=1, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Retrieving connection
[0m15:17:17.898055 [debug] [MainThread]: On master: ROLLBACK
[0m15:17:17.898257 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:17:18.098934 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=01ef2766-6f75-1579-b1ee-64d5ba632a18, name=master, idle-time=1.6689300537109375e-05s, acquire-count=1, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Connection created
[0m15:17:18.100176 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:17:18.100738 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=01ef2766-6f75-1579-b1ee-64d5ba632a18, name=master, idle-time=0.002294778823852539s, acquire-count=1, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Checking idleness
[0m15:17:18.101145 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=01ef2766-6f75-1579-b1ee-64d5ba632a18, name=master, idle-time=0.0027167797088623047s, acquire-count=1, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Retrieving connection
[0m15:17:18.101486 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m15:17:18.101770 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m15:17:18.102112 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5147879728, session-id=01ef2766-6f75-1579-b1ee-64d5ba632a18, name=master, idle-time=1.9073486328125e-06s, acquire-count=0, language=None, thread-identifier=(81697, 8531893760), compute-name=) - Released connection
[0m15:17:18.102722 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:17:18.103052 [debug] [MainThread]: On master: ROLLBACK
[0m15:17:18.103729 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:17:18.104217 [debug] [MainThread]: On master: Close
[0m15:17:18.104675 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef2766-6f75-1579-b1ee-64d5ba632a18) - Closing connection
[0m15:17:18.193753 [debug] [MainThread]: Connection 'model.my_dbt.dbt_model' was properly closed.
[0m15:17:18.194896 [debug] [MainThread]: On model.my_dbt.dbt_model: ROLLBACK
[0m15:17:18.195541 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:17:18.195970 [debug] [MainThread]: On model.my_dbt.dbt_model: Close
[0m15:17:18.196403 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef2766-6d2f-1501-b7aa-48874c3833e2) - Closing connection
[0m15:17:18.293468 [info ] [MainThread]: 
[0m15:17:18.294400 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 4.35 seconds (4.35s).
[0m15:17:18.295564 [debug] [MainThread]: Command end result
[0m15:17:18.330574 [info ] [MainThread]: 
[0m15:17:18.330994 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:17:18.331215 [info ] [MainThread]: 
[0m15:17:18.331466 [error] [MainThread]:   Runtime Error in model dbt_model (models/example/dbt_model.sql)
  PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
[0m15:17:18.331656 [info ] [MainThread]: 
[0m15:17:18.331864 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:17:18.333968 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 5.933715, "process_user_time": 4.097324, "process_kernel_time": 0.30669, "process_mem_max_rss": "225214464", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:17:18.334443 [debug] [MainThread]: Command `dbt run` failed at 15:17:18.334373 after 5.93 seconds
[0m15:17:18.334765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104057200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046b1a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045fbfb0>]}
[0m15:17:18.335010 [debug] [MainThread]: Flushing usage events
[0m15:19:02.045141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052726c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10596a660>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10596a630>]}


============================== 15:19:02.049288 | 877eb062-337f-4bf7-8374-240982fad84c ==============================
[0m15:19:02.049288 [info ] [MainThread]: Running with dbt=1.8.2
[0m15:19:02.049753 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yash/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/yash/my_dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:19:02.105579 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:19:02.107259 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:19:02.107511 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:19:03.088086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '877eb062-337f-4bf7-8374-240982fad84c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129375eb0>]}
[0m15:19:03.125304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '877eb062-337f-4bf7-8374-240982fad84c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060af5f0>]}
[0m15:19:03.125758 [info ] [MainThread]: Registered adapter: databricks=1.8.1
[0m15:19:03.141093 [debug] [MainThread]: checksum: f0a141b9de567cb7f131613ba2682f40b3a1c6a157f81c6e5435862eff68f109, vars: {}, profile: , target: , version: 1.8.2
[0m15:19:03.229211 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:19:03.229547 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:19:03.252651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '877eb062-337f-4bf7-8374-240982fad84c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128df7bf0>]}
[0m15:19:03.370699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '877eb062-337f-4bf7-8374-240982fad84c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1294748f0>]}
[0m15:19:03.371069 [info ] [MainThread]: Found 1 model, 1 source, 586 macros
[0m15:19:03.371314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '877eb062-337f-4bf7-8374-240982fad84c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128db9c10>]}
[0m15:19:03.372427 [info ] [MainThread]: 
[0m15:19:03.372888 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Creating connection
[0m15:19:03.373111 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:19:03.373354 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=None, name=master, idle-time=3.814697265625e-06s, acquire-count=1, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Acquired connection on thread (81735, 8531893760), using default compute resource
[0m15:19:03.374097 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=None, name=list_system, idle-time=0s, acquire-count=0, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Creating connection
[0m15:19:03.374408 [debug] [ThreadPool]: Acquiring new databricks connection 'list_system'
[0m15:19:03.374651 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=None, name=list_system, idle-time=2.1457672119140625e-06s, acquire-count=1, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Acquired connection on thread (81735, 6144929792), using default compute resource
[0m15:19:03.374900 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=None, name=list_system, idle-time=0.00026416778564453125s, acquire-count=1, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Checking idleness
[0m15:19:03.375111 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=None, name=list_system, idle-time=0.00047516822814941406s, acquire-count=1, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Retrieving connection
[0m15:19:03.375288 [debug] [ThreadPool]: Using databricks connection "list_system"
[0m15:19:03.375466 [debug] [ThreadPool]: On list_system: GetSchemas(database=system, schema=None)
[0m15:19:03.375635 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:19:03.746982 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=list_system, idle-time=1.5020370483398438e-05s, acquire-count=1, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Connection created
[0m15:19:03.748155 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, command-id=Unknown) - Created cursor
[0m15:19:04.160573 [debug] [ThreadPool]: SQL status: OK in 0.7799999713897705 seconds
[0m15:19:04.164934 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, command-id=01ef2766-ae83-12b9-aaca-620dabba18b8) - Closing cursor
[0m15:19:04.165538 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=list_system, idle-time=4.0531158447265625e-06s, acquire-count=0, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Released connection
[0m15:19:04.166762 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=list_system, idle-time=0.0012331008911132812s, acquire-count=0, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Checking idleness
[0m15:19:04.167166 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_system, now list_system_billing)
[0m15:19:04.167535 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=list_system_billing, idle-time=0.0020232200622558594s, acquire-count=0, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Reusing connection previously named list_system
[0m15:19:04.167854 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=list_system_billing, idle-time=0.0023491382598876953s, acquire-count=1, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Acquired connection on thread (81735, 6144929792), using default compute resource
[0m15:19:04.178826 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=list_system_billing, idle-time=0.013304948806762695s, acquire-count=1, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Checking idleness
[0m15:19:04.179167 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=list_system_billing, idle-time=0.013669013977050781s, acquire-count=1, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Retrieving connection
[0m15:19:04.179447 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=list_system_billing, idle-time=0.013958215713500977s, acquire-count=1, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Checking idleness
[0m15:19:04.179695 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=list_system_billing, idle-time=0.014213085174560547s, acquire-count=1, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Retrieving connection
[0m15:19:04.179907 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m15:19:04.180099 [debug] [ThreadPool]: Using databricks connection "list_system_billing"
[0m15:19:04.180335 [debug] [ThreadPool]: On list_system_billing: /* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "connection_name": "list_system_billing"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_schema = 'billing'
    
  
[0m15:19:04.180563 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, command-id=Unknown) - Created cursor
[0m15:19:04.667467 [debug] [ThreadPool]: SQL status: OK in 0.49000000953674316 seconds
[0m15:19:04.670582 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, command-id=01ef2766-aebc-1e52-a1a8-acc41b667dc1) - Closing cursor
[0m15:19:04.671288 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=list_system_billing, idle-time=3.814697265625e-06s, acquire-count=0, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Released connection
[0m15:19:04.672339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '877eb062-337f-4bf7-8374-240982fad84c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12975fa70>]}
[0m15:19:04.672824 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=None, name=master, idle-time=1.2994771003723145s, acquire-count=1, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Checking idleness
[0m15:19:04.673121 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=None, name=master, idle-time=1.2997798919677734s, acquire-count=1, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Retrieving connection
[0m15:19:04.673400 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=None, name=master, idle-time=1.3000688552856445s, acquire-count=1, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Checking idleness
[0m15:19:04.673670 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=None, name=master, idle-time=1.300342082977295s, acquire-count=1, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Retrieving connection
[0m15:19:04.673917 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m15:19:04.674144 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m15:19:04.674402 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=None, name=master, idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Released connection
[0m15:19:04.674764 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:19:04.675041 [info ] [MainThread]: 
[0m15:19:04.678175 [debug] [Thread-1 (]: Began running node model.my_dbt.dbt_model
[0m15:19:04.678645 [info ] [Thread-1 (]: 1 of 1 START sql view model billing.dbt_model .................................. [RUN]
[0m15:19:04.679067 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=list_system_billing, idle-time=0.007771015167236328s, acquire-count=0, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Checking idleness
[0m15:19:04.679308 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_system_billing, now model.my_dbt.dbt_model)
[0m15:19:04.679596 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=model.my_dbt.dbt_model, idle-time=0.008308172225952148s, acquire-count=0, language=None, thread-identifier=(81735, 6144929792), compute-name=) - Reusing connection previously named list_system_billing
[0m15:19:04.679881 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=model.my_dbt.dbt_model, idle-time=0.008597135543823242s, acquire-count=1, language=sql, thread-identifier=(81735, 6144929792), compute-name=) - Acquired connection on thread (81735, 6144929792), using default compute resource for model '`system`.`billing`.`dbt_model`'
[0m15:19:04.680139 [debug] [Thread-1 (]: Began compiling node model.my_dbt.dbt_model
[0m15:19:04.686841 [debug] [Thread-1 (]: Writing injected SQL for node "model.my_dbt.dbt_model"
[0m15:19:04.687401 [debug] [Thread-1 (]: Began executing node model.my_dbt.dbt_model
[0m15:19:04.709503 [debug] [Thread-1 (]: Writing runtime sql for node "model.my_dbt.dbt_model"
[0m15:19:04.710833 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=model.my_dbt.dbt_model, idle-time=0.039537906646728516s, acquire-count=1, language=sql, thread-identifier=(81735, 6144929792), compute-name=) - Checking idleness
[0m15:19:04.711149 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=model.my_dbt.dbt_model, idle-time=0.039872169494628906s, acquire-count=1, language=sql, thread-identifier=(81735, 6144929792), compute-name=) - Retrieving connection
[0m15:19:04.711352 [debug] [Thread-1 (]: Using databricks connection "model.my_dbt.dbt_model"
[0m15:19:04.711621 [debug] [Thread-1 (]: On model.my_dbt.dbt_model: /* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "node_id": "model.my_dbt.dbt_model"} */
create or replace view `system`.`billing`.`dbt_model`
  
  
  
  as
    with source_data as (
    select * from `system`.`billing`.`list_prices`
)

select
    account_id,
    cloud
from source_data
where cloud='AZURE'

[0m15:19:04.711903 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, command-id=Unknown) - Created cursor
[0m15:19:05.946376 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, command-id=Unknown) - Closing cursor
[0m15:19:05.948875 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "node_id": "model.my_dbt.dbt_model"} */
create or replace view `system`.`billing`.`dbt_model`
  
  
  
  as
    with source_data as (
    select * from `system`.`billing`.`list_prices`
)

select
    account_id,
    cloud
from source_data
where cloud='AZURE'

: PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNAUTHORIZED_ACCESS] com.databricks.sql.managedcatalog.acl.UnauthorizedAccessException: PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:718)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:45)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:103)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:560)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:429)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:427)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:481)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:464)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:190)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:185)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: com.databricks.sql.managedcatalog.acl.UnauthorizedAccessException: PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
	at com.databricks.managedcatalog.UCReliableHttpClient.reliablyAndTranslateExceptions(UCReliableHttpClient.scala:87)
	at com.databricks.managedcatalog.UCReliableHttpClient.postJson(UCReliableHttpClient.scala:103)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.createTableInternal(ManagedCatalogClientImpl.scala:889)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$createTable$1(ManagedCatalogClientImpl.scala:998)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapException$2(ManagedCatalogClientImpl.scala:4920)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapException$1(ManagedCatalogClientImpl.scala:4919)
	at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException(ErrorDetailsHandler.scala:26)
	at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException$(ErrorDetailsHandler.scala:24)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:163)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:4916)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.createTable(ManagedCatalogClientImpl.scala:991)
	at com.databricks.sql.managedcatalog.PermissionEnforcingManagedCatalog.createManagedOrExternalTable(PermissionEnforcingManagedCatalog.scala:87)
	at com.databricks.sql.managedcatalog.PermissionEnforcingManagedCatalog.createTable(PermissionEnforcingManagedCatalog.scala:287)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$createTable$1(ProfiledManagedCatalog.scala:181)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:717)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:62)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:61)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.createTable(ProfiledManagedCatalog.scala:181)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.createTableInternal(ManagedCatalogSessionCatalog.scala:789)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.createTable(ManagedCatalogSessionCatalog.scala:725)
	at com.databricks.sql.DatabricksSessionCatalog.createTable(DatabricksSessionCatalog.scala:225)
	at org.apache.spark.sql.execution.command.CreateViewCommand.run(views.scala:250)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:84)
	at org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)
	at org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:84)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:81)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:80)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:94)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$5(QueryExecution.scala:375)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$4(QueryExecution.scala:375)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:166)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:375)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$9(SQLExecution.scala:386)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:669)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:275)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1175)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:162)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:606)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:371)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1098)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:367)
	at org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:318)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:364)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:340)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:477)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:83)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:477)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:40)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:343)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:339)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:453)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:340)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:400)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:340)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:277)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:274)
	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:310)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.getOrCreateDF(SparkExecuteStatementOperation.scala:500)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.analyzeQuery(SparkExecuteStatementOperation.scala:523)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$5(SparkExecuteStatementOperation.scala:598)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:531)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:598)
	... 36 more
, operation-id=01ef2766-af0f-17f7-bea1-5de1e828a884
[0m15:19:05.950846 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=model.my_dbt.dbt_model, idle-time=1.0967254638671875e-05s, acquire-count=0, language=sql, thread-identifier=(81735, 6144929792), compute-name=) - Released connection
[0m15:19:05.964820 [debug] [Thread-1 (]: Runtime Error in model dbt_model (models/example/dbt_model.sql)
  PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
[0m15:19:05.965484 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4987503104, session-id=01ef2766-ae6c-1670-80d9-e3abb39addec, name=model.my_dbt.dbt_model, idle-time=6.198883056640625e-06s, acquire-count=0, language=sql, thread-identifier=(81735, 6144929792), compute-name=) - Released connection
[0m15:19:05.967020 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '877eb062-337f-4bf7-8374-240982fad84c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060483b0>]}
[0m15:19:05.967681 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model billing.dbt_model ......................... [[31mERROR[0m in 1.29s]
[0m15:19:05.968270 [debug] [Thread-1 (]: Finished running node model.my_dbt.dbt_model
[0m15:19:05.970047 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=None, name=master, idle-time=1.2956211566925049s, acquire-count=0, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Checking idleness
[0m15:19:05.970400 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=None, name=master, idle-time=1.2959930896759033s, acquire-count=0, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Reusing connection previously named master
[0m15:19:05.970704 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=None, name=master, idle-time=1.2962989807128906s, acquire-count=1, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Acquired connection on thread (81735, 8531893760), using default compute resource
[0m15:19:05.971013 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=None, name=master, idle-time=1.296604871749878s, acquire-count=1, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Checking idleness
[0m15:19:05.971286 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=None, name=master, idle-time=1.2968909740447998s, acquire-count=1, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Retrieving connection
[0m15:19:05.971541 [debug] [MainThread]: On master: ROLLBACK
[0m15:19:05.971770 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:19:06.172608 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=01ef2766-afde-1a8a-8a5d-041e6805bf0c, name=master, idle-time=1.3828277587890625e-05s, acquire-count=1, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Connection created
[0m15:19:06.173965 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:19:06.174598 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=01ef2766-afde-1a8a-8a5d-041e6805bf0c, name=master, idle-time=0.0023467540740966797s, acquire-count=1, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Checking idleness
[0m15:19:06.175057 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=01ef2766-afde-1a8a-8a5d-041e6805bf0c, name=master, idle-time=0.002821683883666992s, acquire-count=1, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Retrieving connection
[0m15:19:06.175431 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m15:19:06.175788 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m15:19:06.176195 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4987505600, session-id=01ef2766-afde-1a8a-8a5d-041e6805bf0c, name=master, idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(81735, 8531893760), compute-name=) - Released connection
[0m15:19:06.176847 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:19:06.177248 [debug] [MainThread]: On master: ROLLBACK
[0m15:19:06.177606 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:19:06.177956 [debug] [MainThread]: On master: Close
[0m15:19:06.178350 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef2766-afde-1a8a-8a5d-041e6805bf0c) - Closing connection
[0m15:19:06.263858 [debug] [MainThread]: Connection 'model.my_dbt.dbt_model' was properly closed.
[0m15:19:06.264937 [debug] [MainThread]: On model.my_dbt.dbt_model: ROLLBACK
[0m15:19:06.265742 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:19:06.266435 [debug] [MainThread]: On model.my_dbt.dbt_model: Close
[0m15:19:06.267181 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef2766-ae6c-1670-80d9-e3abb39addec) - Closing connection
[0m15:19:06.360030 [info ] [MainThread]: 
[0m15:19:06.361001 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.99 seconds (2.99s).
[0m15:19:06.362156 [debug] [MainThread]: Command end result
[0m15:19:06.391927 [info ] [MainThread]: 
[0m15:19:06.392272 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:19:06.392491 [info ] [MainThread]: 
[0m15:19:06.392749 [error] [MainThread]:   Runtime Error in model dbt_model (models/example/dbt_model.sql)
  PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
[0m15:19:06.392940 [info ] [MainThread]: 
[0m15:19:06.393144 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:19:06.395588 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 4.395334, "process_user_time": 3.918992, "process_kernel_time": 0.293932, "process_mem_max_rss": "222101504", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:19:06.396057 [debug] [MainThread]: Command `dbt run` failed at 15:19:06.395986 after 4.40 seconds
[0m15:19:06.396379 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10676a990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bca9f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128cde420>]}
[0m15:19:06.396635 [debug] [MainThread]: Flushing usage events
[0m15:23:46.533102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107011e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067366f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067366c0>]}


============================== 15:23:46.537170 | e387483d-665c-4fc0-a874-8da7b7c643d4 ==============================
[0m15:23:46.537170 [info ] [MainThread]: Running with dbt=1.8.2
[0m15:23:46.537610 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/yash/my_dbt/logs', 'version_check': 'True', 'profiles_dir': '/Users/yash/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:23:46.593489 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:23:46.593929 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:23:46.594186 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:23:47.810241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e387483d-665c-4fc0-a874-8da7b7c643d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15e73dcd0>]}
[0m15:23:47.847617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e387483d-665c-4fc0-a874-8da7b7c643d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107cd8260>]}
[0m15:23:47.848055 [info ] [MainThread]: Registered adapter: databricks=1.8.1
[0m15:23:47.864335 [debug] [MainThread]: checksum: f0a141b9de567cb7f131613ba2682f40b3a1c6a157f81c6e5435862eff68f109, vars: {}, profile: , target: , version: 1.8.2
[0m15:23:47.952770 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:23:47.953098 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:23:47.976254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e387483d-665c-4fc0-a874-8da7b7c643d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15ee6e0f0>]}
[0m15:23:48.101283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e387483d-665c-4fc0-a874-8da7b7c643d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15ef79760>]}
[0m15:23:48.101655 [info ] [MainThread]: Found 1 model, 1 source, 586 macros
[0m15:23:48.101898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e387483d-665c-4fc0-a874-8da7b7c643d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15e8b9cd0>]}
[0m15:23:48.103019 [info ] [MainThread]: 
[0m15:23:48.103462 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Creating connection
[0m15:23:48.103706 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:23:48.103918 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=None, name=master, idle-time=5.245208740234375e-06s, acquire-count=1, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Acquired connection on thread (81809, 8531893760), using default compute resource
[0m15:23:48.104641 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=None, name=list_system, idle-time=0s, acquire-count=0, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Creating connection
[0m15:23:48.104958 [debug] [ThreadPool]: Acquiring new databricks connection 'list_system'
[0m15:23:48.105176 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=None, name=list_system, idle-time=3.0994415283203125e-06s, acquire-count=1, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Acquired connection on thread (81809, 6147354624), using default compute resource
[0m15:23:48.105405 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=None, name=list_system, idle-time=0.0002391338348388672s, acquire-count=1, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Checking idleness
[0m15:23:48.105604 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=None, name=list_system, idle-time=0.0004410743713378906s, acquire-count=1, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Retrieving connection
[0m15:23:48.105777 [debug] [ThreadPool]: Using databricks connection "list_system"
[0m15:23:48.105952 [debug] [ThreadPool]: On list_system: GetSchemas(database=system, schema=None)
[0m15:23:48.106118 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:23:48.369629 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=list_system, idle-time=2.47955322265625e-05s, acquire-count=1, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Connection created
[0m15:23:48.371348 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2767-5815-190b-928f-f0f67b38b34d, command-id=Unknown) - Created cursor
[0m15:23:48.832996 [debug] [ThreadPool]: SQL status: OK in 0.7300000190734863 seconds
[0m15:23:48.847120 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2767-5815-190b-928f-f0f67b38b34d, command-id=01ef2767-582a-1b99-838c-b2ad90a2b3d6) - Closing cursor
[0m15:23:48.847568 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=list_system, idle-time=3.814697265625e-06s, acquire-count=0, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Released connection
[0m15:23:48.848582 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=list_system, idle-time=0.0010099411010742188s, acquire-count=0, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Checking idleness
[0m15:23:48.848927 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_system, now list_system_billing)
[0m15:23:48.849204 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=list_system_billing, idle-time=0.0016546249389648438s, acquire-count=0, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Reusing connection previously named list_system
[0m15:23:48.849462 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=list_system_billing, idle-time=0.0019156932830810547s, acquire-count=1, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Acquired connection on thread (81809, 6147354624), using default compute resource
[0m15:23:48.859248 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=list_system_billing, idle-time=0.01168680191040039s, acquire-count=1, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Checking idleness
[0m15:23:48.859534 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=list_system_billing, idle-time=0.01199483871459961s, acquire-count=1, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Retrieving connection
[0m15:23:48.859769 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=list_system_billing, idle-time=0.012235641479492188s, acquire-count=1, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Checking idleness
[0m15:23:48.859976 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=list_system_billing, idle-time=0.012447834014892578s, acquire-count=1, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Retrieving connection
[0m15:23:48.860159 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m15:23:48.860318 [debug] [ThreadPool]: Using databricks connection "list_system_billing"
[0m15:23:48.860542 [debug] [ThreadPool]: On list_system_billing: /* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "connection_name": "list_system_billing"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_schema = 'billing'
    
  
[0m15:23:48.860765 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2767-5815-190b-928f-f0f67b38b34d, command-id=Unknown) - Created cursor
[0m15:23:49.344469 [debug] [ThreadPool]: SQL status: OK in 0.47999998927116394 seconds
[0m15:23:49.347596 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2767-5815-190b-928f-f0f67b38b34d, command-id=01ef2767-586d-181d-9931-bd8e3bf8e9a8) - Closing cursor
[0m15:23:49.348185 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=list_system_billing, idle-time=5.0067901611328125e-06s, acquire-count=0, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Released connection
[0m15:23:49.349111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e387483d-665c-4fc0-a874-8da7b7c643d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15ee837d0>]}
[0m15:23:49.349541 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=None, name=master, idle-time=1.2456083297729492s, acquire-count=1, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Checking idleness
[0m15:23:49.349847 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=None, name=master, idle-time=1.2459182739257812s, acquire-count=1, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Retrieving connection
[0m15:23:49.350134 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=None, name=master, idle-time=1.2462141513824463s, acquire-count=1, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Checking idleness
[0m15:23:49.350399 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=None, name=master, idle-time=1.2464823722839355s, acquire-count=1, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Retrieving connection
[0m15:23:49.350656 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m15:23:49.350884 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m15:23:49.351143 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=None, name=master, idle-time=1.9073486328125e-06s, acquire-count=0, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Released connection
[0m15:23:49.351490 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:23:49.351772 [info ] [MainThread]: 
[0m15:23:49.353915 [debug] [Thread-1 (]: Began running node model.my_dbt.dbt_model
[0m15:23:49.354325 [info ] [Thread-1 (]: 1 of 1 START sql view model billing.dbt_model .................................. [RUN]
[0m15:23:49.354721 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=list_system_billing, idle-time=0.006514072418212891s, acquire-count=0, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Checking idleness
[0m15:23:49.354948 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_system_billing, now model.my_dbt.dbt_model)
[0m15:23:49.355218 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=model.my_dbt.dbt_model, idle-time=0.0070171356201171875s, acquire-count=0, language=None, thread-identifier=(81809, 6147354624), compute-name=) - Reusing connection previously named list_system_billing
[0m15:23:49.355501 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=model.my_dbt.dbt_model, idle-time=0.007297039031982422s, acquire-count=1, language=sql, thread-identifier=(81809, 6147354624), compute-name=) - Acquired connection on thread (81809, 6147354624), using default compute resource for model '`system`.`billing`.`dbt_model`'
[0m15:23:49.355754 [debug] [Thread-1 (]: Began compiling node model.my_dbt.dbt_model
[0m15:23:49.362493 [debug] [Thread-1 (]: Writing injected SQL for node "model.my_dbt.dbt_model"
[0m15:23:49.363058 [debug] [Thread-1 (]: Began executing node model.my_dbt.dbt_model
[0m15:23:49.385356 [debug] [Thread-1 (]: Writing runtime sql for node "model.my_dbt.dbt_model"
[0m15:23:49.386402 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=model.my_dbt.dbt_model, idle-time=0.03819608688354492s, acquire-count=1, language=sql, thread-identifier=(81809, 6147354624), compute-name=) - Checking idleness
[0m15:23:49.386688 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=model.my_dbt.dbt_model, idle-time=0.038498878479003906s, acquire-count=1, language=sql, thread-identifier=(81809, 6147354624), compute-name=) - Retrieving connection
[0m15:23:49.386876 [debug] [Thread-1 (]: Using databricks connection "model.my_dbt.dbt_model"
[0m15:23:49.387123 [debug] [Thread-1 (]: On model.my_dbt.dbt_model: /* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "node_id": "model.my_dbt.dbt_model"} */
create or replace view `system`.`billing`.`dbt_model`
  
  
  
  as
    with source_data as (
    select * from `system`.`billing`.`list_prices`
)

select
    account_id,
    cloud
from source_data
where cloud='AZURE'

[0m15:23:49.387375 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01ef2767-5815-190b-928f-f0f67b38b34d, command-id=Unknown) - Created cursor
[0m15:23:50.720560 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01ef2767-5815-190b-928f-f0f67b38b34d, command-id=Unknown) - Closing cursor
[0m15:23:50.722749 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "node_id": "model.my_dbt.dbt_model"} */
create or replace view `system`.`billing`.`dbt_model`
  
  
  
  as
    with source_data as (
    select * from `system`.`billing`.`list_prices`
)

select
    account_id,
    cloud
from source_data
where cloud='AZURE'

: PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNAUTHORIZED_ACCESS] com.databricks.sql.managedcatalog.acl.UnauthorizedAccessException: PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:718)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:45)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:103)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:560)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:429)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:427)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:481)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:464)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:190)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:185)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: com.databricks.sql.managedcatalog.acl.UnauthorizedAccessException: PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
	at com.databricks.managedcatalog.UCReliableHttpClient.reliablyAndTranslateExceptions(UCReliableHttpClient.scala:87)
	at com.databricks.managedcatalog.UCReliableHttpClient.postJson(UCReliableHttpClient.scala:103)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.createTableInternal(ManagedCatalogClientImpl.scala:889)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$createTable$1(ManagedCatalogClientImpl.scala:998)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapException$2(ManagedCatalogClientImpl.scala:4920)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapException$1(ManagedCatalogClientImpl.scala:4919)
	at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException(ErrorDetailsHandler.scala:26)
	at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException$(ErrorDetailsHandler.scala:24)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:163)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:4916)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.createTable(ManagedCatalogClientImpl.scala:991)
	at com.databricks.sql.managedcatalog.PermissionEnforcingManagedCatalog.createManagedOrExternalTable(PermissionEnforcingManagedCatalog.scala:87)
	at com.databricks.sql.managedcatalog.PermissionEnforcingManagedCatalog.createTable(PermissionEnforcingManagedCatalog.scala:287)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$createTable$1(ProfiledManagedCatalog.scala:181)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:717)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:62)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:61)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.createTable(ProfiledManagedCatalog.scala:181)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.createTableInternal(ManagedCatalogSessionCatalog.scala:789)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.createTable(ManagedCatalogSessionCatalog.scala:725)
	at com.databricks.sql.DatabricksSessionCatalog.createTable(DatabricksSessionCatalog.scala:225)
	at org.apache.spark.sql.execution.command.CreateViewCommand.run(views.scala:250)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:84)
	at org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)
	at org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:84)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:81)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:80)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:94)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$5(QueryExecution.scala:375)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$4(QueryExecution.scala:375)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:166)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:375)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$9(SQLExecution.scala:386)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:669)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:275)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1175)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:162)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:606)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:371)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1098)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:367)
	at org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:318)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:364)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:340)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:477)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:83)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:477)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:40)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:343)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:339)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:453)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:340)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:400)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:340)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:277)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:274)
	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:310)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.getOrCreateDF(SparkExecuteStatementOperation.scala:500)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.analyzeQuery(SparkExecuteStatementOperation.scala:523)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$5(SparkExecuteStatementOperation.scala:598)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:531)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:598)
	... 36 more
, operation-id=01ef2767-58bc-1a76-a7f8-ae94cf431ccb
[0m15:23:50.724653 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=model.my_dbt.dbt_model, idle-time=6.9141387939453125e-06s, acquire-count=0, language=sql, thread-identifier=(81809, 6147354624), compute-name=) - Released connection
[0m15:23:50.738188 [debug] [Thread-1 (]: Runtime Error in model dbt_model (models/example/dbt_model.sql)
  PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
[0m15:23:50.738720 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5888254768, session-id=01ef2767-5815-190b-928f-f0f67b38b34d, name=model.my_dbt.dbt_model, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(81809, 6147354624), compute-name=) - Released connection
[0m15:23:50.740249 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e387483d-665c-4fc0-a874-8da7b7c643d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070105f0>]}
[0m15:23:50.740920 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model billing.dbt_model ......................... [[31mERROR[0m in 1.38s]
[0m15:23:50.741504 [debug] [Thread-1 (]: Finished running node model.my_dbt.dbt_model
[0m15:23:50.743175 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=None, name=master, idle-time=1.392014980316162s, acquire-count=0, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Checking idleness
[0m15:23:50.743518 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=None, name=master, idle-time=1.3923709392547607s, acquire-count=0, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Reusing connection previously named master
[0m15:23:50.743799 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=None, name=master, idle-time=1.392655849456787s, acquire-count=1, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Acquired connection on thread (81809, 8531893760), using default compute resource
[0m15:23:50.744086 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=None, name=master, idle-time=1.3929479122161865s, acquire-count=1, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Checking idleness
[0m15:23:50.744331 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=None, name=master, idle-time=1.3932020664215088s, acquire-count=1, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Retrieving connection
[0m15:23:50.744538 [debug] [MainThread]: On master: ROLLBACK
[0m15:23:50.744733 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:23:50.974225 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=01ef2767-59a2-19dd-820c-51621015f344, name=master, idle-time=1.5974044799804688e-05s, acquire-count=1, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Connection created
[0m15:23:50.975118 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:23:50.975676 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=01ef2767-59a2-19dd-820c-51621015f344, name=master, idle-time=0.0018219947814941406s, acquire-count=1, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Checking idleness
[0m15:23:50.976122 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=01ef2767-59a2-19dd-820c-51621015f344, name=master, idle-time=0.0022821426391601562s, acquire-count=1, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Retrieving connection
[0m15:23:50.976516 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m15:23:50.976897 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m15:23:50.977320 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5888252128, session-id=01ef2767-59a2-19dd-820c-51621015f344, name=master, idle-time=2.86102294921875e-06s, acquire-count=0, language=None, thread-identifier=(81809, 8531893760), compute-name=) - Released connection
[0m15:23:50.977977 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:23:50.978388 [debug] [MainThread]: On master: ROLLBACK
[0m15:23:50.978758 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:23:50.979130 [debug] [MainThread]: On master: Close
[0m15:23:50.979541 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef2767-59a2-19dd-820c-51621015f344) - Closing connection
[0m15:23:51.059443 [debug] [MainThread]: Connection 'model.my_dbt.dbt_model' was properly closed.
[0m15:23:51.060788 [debug] [MainThread]: On model.my_dbt.dbt_model: ROLLBACK
[0m15:23:51.061632 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:23:51.061963 [debug] [MainThread]: On model.my_dbt.dbt_model: Close
[0m15:23:51.062301 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef2767-5815-190b-928f-f0f67b38b34d) - Closing connection
[0m15:23:51.154623 [info ] [MainThread]: 
[0m15:23:51.155593 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 3.05 seconds (3.05s).
[0m15:23:51.156932 [debug] [MainThread]: Command end result
[0m15:23:51.191253 [info ] [MainThread]: 
[0m15:23:51.191655 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:23:51.191875 [info ] [MainThread]: 
[0m15:23:51.192144 [error] [MainThread]:   Runtime Error in model dbt_model (models/example/dbt_model.sql)
  PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
[0m15:23:51.192343 [info ] [MainThread]: 
[0m15:23:51.192556 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:23:51.195081 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 4.707894, "process_user_time": 4.04203, "process_kernel_time": 0.393228, "process_mem_max_rss": "223264768", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:23:51.195777 [debug] [MainThread]: Command `dbt run` failed at 15:23:51.195673 after 4.71 seconds
[0m15:23:51.196111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106446ab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15e472de0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106995e50>]}
[0m15:23:51.196396 [debug] [MainThread]: Flushing usage events
[0m15:26:21.655229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fb64b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076ac860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076ae870>]}


============================== 15:26:21.659380 | 389a3599-c8f8-4266-8fc9-77b6a05edfa8 ==============================
[0m15:26:21.659380 [info ] [MainThread]: Running with dbt=1.8.2
[0m15:26:21.659821 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yash/.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/yash/my_dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:26:21.716864 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:26:21.717282 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:26:21.717525 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:26:22.736389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '389a3599-c8f8-4266-8fc9-77b6a05edfa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076ae330>]}
[0m15:26:22.773678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '389a3599-c8f8-4266-8fc9-77b6a05edfa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076ac9e0>]}
[0m15:26:22.774127 [info ] [MainThread]: Registered adapter: databricks=1.8.1
[0m15:26:22.791218 [debug] [MainThread]: checksum: f0a141b9de567cb7f131613ba2682f40b3a1c6a157f81c6e5435862eff68f109, vars: {}, profile: , target: , version: 1.8.2
[0m15:26:22.882185 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:26:22.882524 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:26:22.905657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '389a3599-c8f8-4266-8fc9-77b6a05edfa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12af71130>]}
[0m15:26:23.026669 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '389a3599-c8f8-4266-8fc9-77b6a05edfa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12c183e90>]}
[0m15:26:23.027035 [info ] [MainThread]: Found 1 model, 1 source, 586 macros
[0m15:26:23.027273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '389a3599-c8f8-4266-8fc9-77b6a05edfa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b78db80>]}
[0m15:26:23.028384 [info ] [MainThread]: 
[0m15:26:23.028823 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Creating connection
[0m15:26:23.029033 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:26:23.029243 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=None, name=master, idle-time=5.0067901611328125e-06s, acquire-count=1, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Acquired connection on thread (81828, 8531893760), using default compute resource
[0m15:26:23.029976 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=None, name=list_system, idle-time=0s, acquire-count=0, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Creating connection
[0m15:26:23.030297 [debug] [ThreadPool]: Acquiring new databricks connection 'list_system'
[0m15:26:23.030534 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=None, name=list_system, idle-time=1.9073486328125e-06s, acquire-count=1, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Acquired connection on thread (81828, 6114242560), using default compute resource
[0m15:26:23.030779 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=None, name=list_system, idle-time=0.0002570152282714844s, acquire-count=1, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Checking idleness
[0m15:26:23.030988 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=None, name=list_system, idle-time=0.0004668235778808594s, acquire-count=1, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Retrieving connection
[0m15:26:23.031168 [debug] [ThreadPool]: Using databricks connection "list_system"
[0m15:26:23.031346 [debug] [ThreadPool]: On list_system: GetSchemas(database=system, schema=None)
[0m15:26:23.031516 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:26:23.467285 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=list_system, idle-time=1.5735626220703125e-05s, acquire-count=1, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Connection created
[0m15:26:23.468729 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2767-b483-1636-b31e-0e07873a26e6, command-id=Unknown) - Created cursor
[0m15:26:24.080335 [debug] [ThreadPool]: SQL status: OK in 1.0499999523162842 seconds
[0m15:26:24.086376 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2767-b483-1636-b31e-0e07873a26e6, command-id=01ef2767-b49a-1232-81b6-79e67d51ef81) - Closing cursor
[0m15:26:24.087112 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=list_system, idle-time=5.0067901611328125e-06s, acquire-count=0, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Released connection
[0m15:26:24.088684 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=list_system, idle-time=0.0015521049499511719s, acquire-count=0, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Checking idleness
[0m15:26:24.089196 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_system, now list_system_billing)
[0m15:26:24.089622 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=list_system_billing, idle-time=0.0025358200073242188s, acquire-count=0, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Reusing connection previously named list_system
[0m15:26:24.090006 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=list_system_billing, idle-time=0.0029287338256835938s, acquire-count=1, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Acquired connection on thread (81828, 6114242560), using default compute resource
[0m15:26:24.101969 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=list_system_billing, idle-time=0.014888763427734375s, acquire-count=1, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Checking idleness
[0m15:26:24.102366 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=list_system_billing, idle-time=0.015311002731323242s, acquire-count=1, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Retrieving connection
[0m15:26:24.102646 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=list_system_billing, idle-time=0.015599966049194336s, acquire-count=1, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Checking idleness
[0m15:26:24.102894 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=list_system_billing, idle-time=0.015851974487304688s, acquire-count=1, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Retrieving connection
[0m15:26:24.103115 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m15:26:24.103307 [debug] [ThreadPool]: Using databricks connection "list_system_billing"
[0m15:26:24.103558 [debug] [ThreadPool]: On list_system_billing: /* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "connection_name": "list_system_billing"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_schema = 'billing'
    
  
[0m15:26:24.103832 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2767-b483-1636-b31e-0e07873a26e6, command-id=Unknown) - Created cursor
[0m15:26:24.580296 [debug] [ThreadPool]: SQL status: OK in 0.47999998927116394 seconds
[0m15:26:24.585543 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef2767-b483-1636-b31e-0e07873a26e6, command-id=01ef2767-b4fa-1fbd-86c9-173d124b8205) - Closing cursor
[0m15:26:24.586506 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=list_system_billing, idle-time=5.0067901611328125e-06s, acquire-count=0, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Released connection
[0m15:26:24.587703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '389a3599-c8f8-4266-8fc9-77b6a05edfa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12aee3a70>]}
[0m15:26:24.588403 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=None, name=master, idle-time=1.5591011047363281s, acquire-count=1, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Checking idleness
[0m15:26:24.588810 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=None, name=master, idle-time=1.5595450401306152s, acquire-count=1, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Retrieving connection
[0m15:26:24.589195 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=None, name=master, idle-time=1.5599358081817627s, acquire-count=1, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Checking idleness
[0m15:26:24.589542 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=None, name=master, idle-time=1.5602858066558838s, acquire-count=1, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Retrieving connection
[0m15:26:24.589858 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m15:26:24.590154 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m15:26:24.590450 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=None, name=master, idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Released connection
[0m15:26:24.590847 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:26:24.591146 [info ] [MainThread]: 
[0m15:26:24.594404 [debug] [Thread-1 (]: Began running node model.my_dbt.dbt_model
[0m15:26:24.594926 [info ] [Thread-1 (]: 1 of 1 START sql view model billing.dbt_model .................................. [RUN]
[0m15:26:24.595433 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=list_system_billing, idle-time=0.008919239044189453s, acquire-count=0, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Checking idleness
[0m15:26:24.595735 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_system_billing, now model.my_dbt.dbt_model)
[0m15:26:24.596073 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=model.my_dbt.dbt_model, idle-time=0.009567022323608398s, acquire-count=0, language=None, thread-identifier=(81828, 6114242560), compute-name=) - Reusing connection previously named list_system_billing
[0m15:26:24.596402 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=model.my_dbt.dbt_model, idle-time=0.009914875030517578s, acquire-count=1, language=sql, thread-identifier=(81828, 6114242560), compute-name=) - Acquired connection on thread (81828, 6114242560), using default compute resource for model '`system`.`billing`.`dbt_model`'
[0m15:26:24.596667 [debug] [Thread-1 (]: Began compiling node model.my_dbt.dbt_model
[0m15:26:24.603868 [debug] [Thread-1 (]: Writing injected SQL for node "model.my_dbt.dbt_model"
[0m15:26:24.604779 [debug] [Thread-1 (]: Began executing node model.my_dbt.dbt_model
[0m15:26:24.628077 [debug] [Thread-1 (]: Writing runtime sql for node "model.my_dbt.dbt_model"
[0m15:26:24.628686 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=model.my_dbt.dbt_model, idle-time=0.04219698905944824s, acquire-count=1, language=sql, thread-identifier=(81828, 6114242560), compute-name=) - Checking idleness
[0m15:26:24.628976 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=model.my_dbt.dbt_model, idle-time=0.042500972747802734s, acquire-count=1, language=sql, thread-identifier=(81828, 6114242560), compute-name=) - Retrieving connection
[0m15:26:24.629169 [debug] [Thread-1 (]: Using databricks connection "model.my_dbt.dbt_model"
[0m15:26:24.629423 [debug] [Thread-1 (]: On model.my_dbt.dbt_model: /* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "node_id": "model.my_dbt.dbt_model"} */
create or replace view `system`.`billing`.`dbt_model`
  
  
  
  as
    with source_data as (
    select * from `system`.`billing`.`list_prices`
)

select
    account_id,
    cloud
from source_data
where cloud='AZURE'

[0m15:26:24.629686 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01ef2767-b483-1636-b31e-0e07873a26e6, command-id=Unknown) - Created cursor
[0m15:26:25.842214 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01ef2767-b483-1636-b31e-0e07873a26e6, command-id=Unknown) - Closing cursor
[0m15:26:25.844053 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "node_id": "model.my_dbt.dbt_model"} */
create or replace view `system`.`billing`.`dbt_model`
  
  
  
  as
    with source_data as (
    select * from `system`.`billing`.`list_prices`
)

select
    account_id,
    cloud
from source_data
where cloud='AZURE'

: PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNAUTHORIZED_ACCESS] com.databricks.sql.managedcatalog.acl.UnauthorizedAccessException: PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:718)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:45)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:103)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:560)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:429)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:427)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:481)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:464)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:190)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:185)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: com.databricks.sql.managedcatalog.acl.UnauthorizedAccessException: PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
	at com.databricks.managedcatalog.UCReliableHttpClient.reliablyAndTranslateExceptions(UCReliableHttpClient.scala:87)
	at com.databricks.managedcatalog.UCReliableHttpClient.postJson(UCReliableHttpClient.scala:103)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.createTableInternal(ManagedCatalogClientImpl.scala:889)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$createTable$1(ManagedCatalogClientImpl.scala:998)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapException$2(ManagedCatalogClientImpl.scala:4920)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapException$1(ManagedCatalogClientImpl.scala:4919)
	at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException(ErrorDetailsHandler.scala:26)
	at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException$(ErrorDetailsHandler.scala:24)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:163)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:4916)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.createTable(ManagedCatalogClientImpl.scala:991)
	at com.databricks.sql.managedcatalog.PermissionEnforcingManagedCatalog.createManagedOrExternalTable(PermissionEnforcingManagedCatalog.scala:87)
	at com.databricks.sql.managedcatalog.PermissionEnforcingManagedCatalog.createTable(PermissionEnforcingManagedCatalog.scala:287)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$createTable$1(ProfiledManagedCatalog.scala:181)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:717)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:62)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:61)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.createTable(ProfiledManagedCatalog.scala:181)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.createTableInternal(ManagedCatalogSessionCatalog.scala:789)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.createTable(ManagedCatalogSessionCatalog.scala:725)
	at com.databricks.sql.DatabricksSessionCatalog.createTable(DatabricksSessionCatalog.scala:225)
	at org.apache.spark.sql.execution.command.CreateViewCommand.run(views.scala:250)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:84)
	at org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)
	at org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:84)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:81)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:80)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:94)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$5(QueryExecution.scala:375)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$4(QueryExecution.scala:375)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:166)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:375)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$9(SQLExecution.scala:386)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:669)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:275)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1175)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:162)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:606)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:371)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1098)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:367)
	at org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:318)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:364)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:340)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:477)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:83)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:477)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:40)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:343)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:339)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:453)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:340)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:400)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:340)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:277)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:274)
	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:310)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.getOrCreateDF(SparkExecuteStatementOperation.scala:500)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.analyzeQuery(SparkExecuteStatementOperation.scala:523)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$5(SparkExecuteStatementOperation.scala:598)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:531)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:598)
	... 36 more
, operation-id=01ef2767-b546-1b56-8471-c248e40397f7
[0m15:26:25.845491 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=model.my_dbt.dbt_model, idle-time=6.9141387939453125e-06s, acquire-count=0, language=sql, thread-identifier=(81828, 6114242560), compute-name=) - Released connection
[0m15:26:25.858902 [debug] [Thread-1 (]: Runtime Error in model dbt_model (models/example/dbt_model.sql)
  PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
[0m15:26:25.859589 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5034905712, session-id=01ef2767-b483-1636-b31e-0e07873a26e6, name=model.my_dbt.dbt_model, idle-time=5.0067901611328125e-06s, acquire-count=0, language=sql, thread-identifier=(81828, 6114242560), compute-name=) - Released connection
[0m15:26:25.861375 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '389a3599-c8f8-4266-8fc9-77b6a05edfa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d90440>]}
[0m15:26:25.862131 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model billing.dbt_model ......................... [[31mERROR[0m in 1.26s]
[0m15:26:25.862799 [debug] [Thread-1 (]: Finished running node model.my_dbt.dbt_model
[0m15:26:25.864520 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=None, name=master, idle-time=1.2740437984466553s, acquire-count=0, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Checking idleness
[0m15:26:25.864896 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=None, name=master, idle-time=1.2744410037994385s, acquire-count=0, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Reusing connection previously named master
[0m15:26:25.865188 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=None, name=master, idle-time=1.2747368812561035s, acquire-count=1, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Acquired connection on thread (81828, 8531893760), using default compute resource
[0m15:26:25.865482 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=None, name=master, idle-time=1.275041103363037s, acquire-count=1, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Checking idleness
[0m15:26:25.865750 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=None, name=master, idle-time=1.2753088474273682s, acquire-count=1, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Retrieving connection
[0m15:26:25.865990 [debug] [MainThread]: On master: ROLLBACK
[0m15:26:25.866216 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:26:26.089536 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=01ef2767-b618-1ff8-baad-f1a261433551, name=master, idle-time=1.1920928955078125e-05s, acquire-count=1, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Connection created
[0m15:26:26.090814 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:26:26.091338 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=01ef2767-b618-1ff8-baad-f1a261433551, name=master, idle-time=0.0021708011627197266s, acquire-count=1, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Checking idleness
[0m15:26:26.091747 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=01ef2767-b618-1ff8-baad-f1a261433551, name=master, idle-time=0.0025877952575683594s, acquire-count=1, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Retrieving connection
[0m15:26:26.092092 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m15:26:26.092407 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m15:26:26.092713 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5019250240, session-id=01ef2767-b618-1ff8-baad-f1a261433551, name=master, idle-time=9.5367431640625e-07s, acquire-count=0, language=None, thread-identifier=(81828, 8531893760), compute-name=) - Released connection
[0m15:26:26.093235 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:26:26.093539 [debug] [MainThread]: On master: ROLLBACK
[0m15:26:26.093804 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:26:26.094059 [debug] [MainThread]: On master: Close
[0m15:26:26.094458 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef2767-b618-1ff8-baad-f1a261433551) - Closing connection
[0m15:26:26.192647 [debug] [MainThread]: Connection 'model.my_dbt.dbt_model' was properly closed.
[0m15:26:26.193753 [debug] [MainThread]: On model.my_dbt.dbt_model: ROLLBACK
[0m15:26:26.194578 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m15:26:26.195279 [debug] [MainThread]: On model.my_dbt.dbt_model: Close
[0m15:26:26.196032 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef2767-b483-1636-b31e-0e07873a26e6) - Closing connection
[0m15:26:26.287537 [info ] [MainThread]: 
[0m15:26:26.288367 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 3.26 seconds (3.26s).
[0m15:26:26.289491 [debug] [MainThread]: Command end result
[0m15:26:26.323964 [info ] [MainThread]: 
[0m15:26:26.324352 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:26:26.324578 [info ] [MainThread]: 
[0m15:26:26.324847 [error] [MainThread]:   Runtime Error in model dbt_model (models/example/dbt_model.sql)
  PERMISSION_DENIED: User does not have CREATE TABLE on Schema 'system.billing'.
[0m15:26:26.325042 [info ] [MainThread]: 
[0m15:26:26.325259 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:26:26.327400 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 4.7199955, "process_user_time": 3.976768, "process_kernel_time": 0.293524, "process_mem_max_rss": "216465408", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:26:26.327810 [debug] [MainThread]: Command `dbt run` failed at 15:26:26.327742 after 4.72 seconds
[0m15:26:26.328099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107912810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106774f20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081e1610>]}
[0m15:26:26.328356 [debug] [MainThread]: Flushing usage events
[0m15:45:17.841700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ceee40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106497f20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106497ce0>]}


============================== 15:45:17.845999 | da3cf8fa-7623-4028-a078-090006e5135c ==============================
[0m15:45:17.845999 [info ] [MainThread]: Running with dbt=1.8.2
[0m15:45:17.846458 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yash/.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/yash/my_dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m15:45:17.902598 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:45:17.902983 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:45:17.903227 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:45:19.137277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'da3cf8fa-7623-4028-a078-090006e5135c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065529f0>]}
[0m15:45:19.174271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'da3cf8fa-7623-4028-a078-090006e5135c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1266207a0>]}
[0m15:45:19.174714 [info ] [MainThread]: Registered adapter: databricks=1.8.1
[0m15:45:19.190808 [debug] [MainThread]: checksum: f0a141b9de567cb7f131613ba2682f40b3a1c6a157f81c6e5435862eff68f109, vars: {}, profile: , target: , version: 1.8.2
[0m15:45:19.250573 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m15:45:19.250983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'da3cf8fa-7623-4028-a078-090006e5135c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126703710>]}
[0m15:45:20.327893 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.my_dbt.dbt_model' (models/example/dbt_model.sql) depends on a source named 'default.customer' which was not found
[0m15:45:20.330110 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 2.5360768, "process_user_time": 4.748571, "process_kernel_time": 0.39454, "process_mem_max_rss": "213450752", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:45:20.330533 [debug] [MainThread]: Command `dbt run` failed at 15:45:20.330461 after 2.54 seconds
[0m15:45:20.330804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ceee40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f2c3e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1260f2f60>]}
[0m15:45:20.331050 [debug] [MainThread]: Flushing usage events
[0m15:45:43.211170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c57230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10728e690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10728e660>]}


============================== 15:45:43.215117 | e3290b9d-1594-4b70-99a9-87718bdf5154 ==============================
[0m15:45:43.215117 [info ] [MainThread]: Running with dbt=1.8.2
[0m15:45:43.215570 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yash/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/yash/my_dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:45:43.271339 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:45:43.271757 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:45:43.272004 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:45:44.210539 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e3290b9d-1594-4b70-99a9-87718bdf5154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c9ec30>]}
[0m15:45:44.247399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e3290b9d-1594-4b70-99a9-87718bdf5154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124ef0530>]}
[0m15:45:44.247833 [info ] [MainThread]: Registered adapter: databricks=1.8.1
[0m15:45:44.263231 [debug] [MainThread]: checksum: f0a141b9de567cb7f131613ba2682f40b3a1c6a157f81c6e5435862eff68f109, vars: {}, profile: , target: , version: 1.8.2
[0m15:45:44.321314 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m15:45:44.321757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e3290b9d-1594-4b70-99a9-87718bdf5154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124fd7560>]}
[0m15:45:45.394157 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.my_dbt.dbt_model' (models/example/dbt_model.sql) depends on a source named 'default.customers' which was not found
[0m15:45:45.396750 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 2.2306423, "process_user_time": 4.649379, "process_kernel_time": 0.261013, "process_mem_max_rss": "213417984", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:45:45.397192 [debug] [MainThread]: Command `dbt run` failed at 15:45:45.397123 after 2.23 seconds
[0m15:45:45.397477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10444a9c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125ff4aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124f4af30>]}
[0m15:45:45.397725 [debug] [MainThread]: Flushing usage events
[0m15:47:57.030773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104431b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103b367e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103b367b0>]}


============================== 15:47:57.034851 | be620b39-f9ff-4f72-8d4e-02dba34262e6 ==============================
[0m15:47:57.034851 [info ] [MainThread]: Running with dbt=1.8.2
[0m15:47:57.035305 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yash/.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/yash/my_dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:47:57.093621 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:47:57.094053 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:47:57.094317 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:47:58.338917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'be620b39-f9ff-4f72-8d4e-02dba34262e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14ccd2b10>]}
[0m15:47:58.376542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'be620b39-f9ff-4f72-8d4e-02dba34262e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14cd70440>]}
[0m15:47:58.377017 [info ] [MainThread]: Registered adapter: databricks=1.8.1
[0m15:47:58.392398 [debug] [MainThread]: checksum: f0a141b9de567cb7f131613ba2682f40b3a1c6a157f81c6e5435862eff68f109, vars: {}, profile: , target: , version: 1.8.2
[0m15:47:58.450801 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m15:47:58.451204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'be620b39-f9ff-4f72-8d4e-02dba34262e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14dcd3890>]}
[0m15:47:59.551950 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.my_dbt.dbt_model' (models/example/dbt_model.sql) depends on a source named 'default.customers' which was not found
[0m15:47:59.554882 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 2.570395, "process_user_time": 4.08423, "process_kernel_time": 0.35091, "process_mem_max_rss": "204259328", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:47:59.555303 [debug] [MainThread]: Command `dbt run` failed at 15:47:59.555230 after 2.57 seconds
[0m15:47:59.555579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104845d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14dfc9bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14dfd7560>]}
[0m15:47:59.555823 [debug] [MainThread]: Flushing usage events
[0m15:52:31.823792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10857d970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c36870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c34fb0>]}


============================== 15:52:31.827897 | a55f7bd8-5607-4d3c-b1e1-647e14f79f2e ==============================
[0m15:52:31.827897 [info ] [MainThread]: Running with dbt=1.8.2
[0m15:52:31.828360 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yash/.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/yash/my_dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:52:31.883278 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:52:31.883644 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:52:31.883888 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:52:33.111284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a55f7bd8-5607-4d3c-b1e1-647e14f79f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c36300>]}
[0m15:52:33.148093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a55f7bd8-5607-4d3c-b1e1-647e14f79f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c79c10>]}
[0m15:52:33.148531 [info ] [MainThread]: Registered adapter: databricks=1.8.1
[0m15:52:33.164301 [debug] [MainThread]: checksum: f0a141b9de567cb7f131613ba2682f40b3a1c6a157f81c6e5435862eff68f109, vars: {}, profile: , target: , version: 1.8.2
[0m15:52:33.223904 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m15:52:33.224329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a55f7bd8-5607-4d3c-b1e1-647e14f79f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x136a57560>]}
[0m15:52:34.303740 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.my_dbt.dbt_model' (models/example/dbt_model.sql) depends on a source named 'hive_metstore.customers' which was not found
[0m15:52:34.306660 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 2.530632, "process_user_time": 4.769261, "process_kernel_time": 0.366094, "process_mem_max_rss": "215367680", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:52:34.307088 [debug] [MainThread]: Command `dbt run` failed at 15:52:34.307019 after 2.53 seconds
[0m15:52:34.307363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10857d970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x136e50380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x136892900>]}
[0m15:52:34.307608 [debug] [MainThread]: Flushing usage events
[0m16:09:43.121620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116435c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072e65d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072e65a0>]}


============================== 16:09:43.125638 | 2e28c03c-3cca-4ed9-89f4-15ad19287e84 ==============================
[0m16:09:43.125638 [info ] [MainThread]: Running with dbt=1.8.2
[0m16:09:43.126076 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/yash/.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/yash/my_dbt/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:09:43.183632 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:09:43.184051 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:09:43.184307 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:09:44.411220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2e28c03c-3cca-4ed9-89f4-15ad19287e84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120abef0>]}
[0m16:09:44.448543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2e28c03c-3cca-4ed9-89f4-15ad19287e84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150ad0cb0>]}
[0m16:09:44.448991 [info ] [MainThread]: Registered adapter: databricks=1.8.1
[0m16:09:44.465008 [debug] [MainThread]: checksum: f0a141b9de567cb7f131613ba2682f40b3a1c6a157f81c6e5435862eff68f109, vars: {}, profile: , target: , version: 1.8.2
[0m16:09:44.527231 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m16:09:44.527654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2e28c03c-3cca-4ed9-89f4-15ad19287e84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150c539e0>]}
[0m16:09:45.666430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2e28c03c-3cca-4ed9-89f4-15ad19287e84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150eb9220>]}
[0m16:09:45.730900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2e28c03c-3cca-4ed9-89f4-15ad19287e84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150ef4ad0>]}
[0m16:09:45.731248 [info ] [MainThread]: Found 1 model, 1 source, 586 macros
[0m16:09:45.731488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2e28c03c-3cca-4ed9-89f4-15ad19287e84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150ea9a60>]}
[0m16:09:45.732581 [info ] [MainThread]: 
[0m16:09:45.733022 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Creating connection
[0m16:09:45.733245 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:09:45.733461 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=None, name=master, idle-time=3.814697265625e-06s, acquire-count=1, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Acquired connection on thread (82519, 8531893760), using default compute resource
[0m16:09:45.734054 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=None, name=list_dbt, idle-time=0s, acquire-count=0, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Creating connection
[0m16:09:45.734368 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt'
[0m16:09:45.734600 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=None, name=list_dbt, idle-time=1.9073486328125e-06s, acquire-count=1, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Acquired connection on thread (82519, 6135377920), using default compute resource
[0m16:09:45.734976 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=None, name=list_dbt, idle-time=0.0003829002380371094s, acquire-count=1, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Checking idleness
[0m16:09:45.735196 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=None, name=list_dbt, idle-time=0.0006079673767089844s, acquire-count=1, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Retrieving connection
[0m16:09:45.735377 [debug] [ThreadPool]: Using databricks connection "list_dbt"
[0m16:09:45.735555 [debug] [ThreadPool]: On list_dbt: GetSchemas(database=dbt, schema=None)
[0m16:09:45.735726 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:09:46.031653 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=list_dbt, idle-time=1.1920928955078125e-05s, acquire-count=1, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Connection created
[0m16:09:46.032774 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, command-id=Unknown) - Created cursor
[0m16:09:46.409462 [debug] [ThreadPool]: SQL status: OK in 0.6700000166893005 seconds
[0m16:09:46.420934 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, command-id=01ef276d-c3c7-1f4f-a40f-6e98815c9205) - Closing cursor
[0m16:09:46.421357 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=list_dbt, idle-time=3.814697265625e-06s, acquire-count=0, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Released connection
[0m16:09:46.422302 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=list_dbt, idle-time=0.0009548664093017578s, acquire-count=0, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Checking idleness
[0m16:09:46.422632 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt, now list_dbt_dbt)
[0m16:09:46.422960 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=list_dbt_dbt, idle-time=0.00160980224609375s, acquire-count=0, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Reusing connection previously named list_dbt
[0m16:09:46.423239 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=list_dbt_dbt, idle-time=0.001895904541015625s, acquire-count=1, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Acquired connection on thread (82519, 6135377920), using default compute resource
[0m16:09:46.431222 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=list_dbt_dbt, idle-time=0.00987386703491211s, acquire-count=1, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Checking idleness
[0m16:09:46.431505 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=list_dbt_dbt, idle-time=0.010175943374633789s, acquire-count=1, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Retrieving connection
[0m16:09:46.431740 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=list_dbt_dbt, idle-time=0.010417938232421875s, acquire-count=1, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Checking idleness
[0m16:09:46.431942 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=list_dbt_dbt, idle-time=0.010622978210449219s, acquire-count=1, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Retrieving connection
[0m16:09:46.432125 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m16:09:46.432281 [debug] [ThreadPool]: Using databricks connection "list_dbt_dbt"
[0m16:09:46.432497 [debug] [ThreadPool]: On list_dbt_dbt: /* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "connection_name": "list_dbt_dbt"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `dbt`.`information_schema`.`tables`
    where table_schema = 'dbt'
    
  
[0m16:09:46.432718 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, command-id=Unknown) - Created cursor
[0m16:09:47.227341 [debug] [ThreadPool]: SQL status: OK in 0.7900000214576721 seconds
[0m16:09:47.230884 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, command-id=01ef276d-c404-1f0a-b779-900876c8f3d5) - Closing cursor
[0m16:09:47.231539 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=list_dbt_dbt, idle-time=4.291534423828125e-06s, acquire-count=0, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Released connection
[0m16:09:47.232352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2e28c03c-3cca-4ed9-89f4-15ad19287e84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150e5ce00>]}
[0m16:09:47.232798 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=None, name=master, idle-time=1.499323844909668s, acquire-count=1, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Checking idleness
[0m16:09:47.233094 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=None, name=master, idle-time=1.4996259212493896s, acquire-count=1, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Retrieving connection
[0m16:09:47.233377 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=None, name=master, idle-time=1.4999160766601562s, acquire-count=1, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Checking idleness
[0m16:09:47.233650 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=None, name=master, idle-time=1.5001869201660156s, acquire-count=1, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Retrieving connection
[0m16:09:47.233908 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m16:09:47.234137 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m16:09:47.234395 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=None, name=master, idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Released connection
[0m16:09:47.234771 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:09:47.235064 [info ] [MainThread]: 
[0m16:09:47.237911 [debug] [Thread-1 (]: Began running node model.my_dbt.dbt_model
[0m16:09:47.238359 [info ] [Thread-1 (]: 1 of 1 START sql view model dbt.dbt_model ...................................... [RUN]
[0m16:09:47.238779 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=list_dbt_dbt, idle-time=0.007224082946777344s, acquire-count=0, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Checking idleness
[0m16:09:47.239010 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dbt_dbt, now model.my_dbt.dbt_model)
[0m16:09:47.239287 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=model.my_dbt.dbt_model, idle-time=0.007743120193481445s, acquire-count=0, language=None, thread-identifier=(82519, 6135377920), compute-name=) - Reusing connection previously named list_dbt_dbt
[0m16:09:47.239564 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=model.my_dbt.dbt_model, idle-time=0.008016109466552734s, acquire-count=1, language=sql, thread-identifier=(82519, 6135377920), compute-name=) - Acquired connection on thread (82519, 6135377920), using default compute resource for model '`dbt`.`dbt`.`dbt_model`'
[0m16:09:47.239826 [debug] [Thread-1 (]: Began compiling node model.my_dbt.dbt_model
[0m16:09:47.246249 [debug] [Thread-1 (]: Writing injected SQL for node "model.my_dbt.dbt_model"
[0m16:09:47.247473 [debug] [Thread-1 (]: Began executing node model.my_dbt.dbt_model
[0m16:09:47.269626 [debug] [Thread-1 (]: Writing runtime sql for node "model.my_dbt.dbt_model"
[0m16:09:47.270172 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=model.my_dbt.dbt_model, idle-time=0.03862404823303223s, acquire-count=1, language=sql, thread-identifier=(82519, 6135377920), compute-name=) - Checking idleness
[0m16:09:47.270473 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=model.my_dbt.dbt_model, idle-time=0.038915157318115234s, acquire-count=1, language=sql, thread-identifier=(82519, 6135377920), compute-name=) - Retrieving connection
[0m16:09:47.270670 [debug] [Thread-1 (]: Using databricks connection "model.my_dbt.dbt_model"
[0m16:09:47.270924 [debug] [Thread-1 (]: On model.my_dbt.dbt_model: /* {"app": "dbt", "dbt_version": "1.8.2", "dbt_databricks_version": "1.8.1", "databricks_sql_connector_version": "3.1.2", "profile_name": "my_dbt", "target_name": "dev", "node_id": "model.my_dbt.dbt_model"} */
create or replace view `dbt`.`dbt`.`dbt_model`
  
  
  
  as
    with source_data as (
    select * from `dbt`.`dbt`.`2010_summary`
)

select
    DEST_COUNTRY_NAME,
    ORIGIN_COUNTRY_NAME,
    count
from source_data
where ORIGIN_COUNTRY_NAME='United States'

[0m16:09:47.271187 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, command-id=Unknown) - Created cursor
[0m16:09:48.138763 [debug] [Thread-1 (]: SQL status: OK in 0.8700000047683716 seconds
[0m16:09:48.140235 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, command-id=01ef276d-c47f-11c7-965b-374301a33410) - Closing cursor
[0m16:09:48.158780 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=model.my_dbt.dbt_model, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(82519, 6135377920), compute-name=) - Released connection
[0m16:09:48.159204 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5652824720, session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4, name=model.my_dbt.dbt_model, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(82519, 6135377920), compute-name=) - Released connection
[0m16:09:48.160118 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e28c03c-3cca-4ed9-89f4-15ad19287e84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079c83b0>]}
[0m16:09:48.160578 [info ] [Thread-1 (]: 1 of 1 OK created sql view model dbt.dbt_model ................................. [[32mOK[0m in 0.92s]
[0m16:09:48.160995 [debug] [Thread-1 (]: Finished running node model.my_dbt.dbt_model
[0m16:09:48.161909 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=None, name=master, idle-time=0.9275021553039551s, acquire-count=0, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Checking idleness
[0m16:09:48.162222 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=None, name=master, idle-time=0.92783522605896s, acquire-count=0, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Reusing connection previously named master
[0m16:09:48.162450 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=None, name=master, idle-time=0.9280669689178467s, acquire-count=1, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Acquired connection on thread (82519, 8531893760), using default compute resource
[0m16:09:48.162682 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=None, name=master, idle-time=0.928307294845581s, acquire-count=1, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Checking idleness
[0m16:09:48.162900 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=None, name=master, idle-time=0.9285240173339844s, acquire-count=1, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Retrieving connection
[0m16:09:48.163096 [debug] [MainThread]: On master: ROLLBACK
[0m16:09:48.163278 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:09:48.393712 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=01ef276d-c51d-1e67-afb6-ee1a811c1b9a, name=master, idle-time=1.0013580322265625e-05s, acquire-count=1, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Connection created
[0m16:09:48.394551 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m16:09:48.395114 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=01ef276d-c51d-1e67-afb6-ee1a811c1b9a, name=master, idle-time=0.0016598701477050781s, acquire-count=1, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Checking idleness
[0m16:09:48.395569 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=01ef276d-c51d-1e67-afb6-ee1a811c1b9a, name=master, idle-time=0.002124786376953125s, acquire-count=1, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Retrieving connection
[0m16:09:48.395948 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m16:09:48.396300 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m16:09:48.396706 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5652824912, session-id=01ef276d-c51d-1e67-afb6-ee1a811c1b9a, name=master, idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(82519, 8531893760), compute-name=) - Released connection
[0m16:09:48.397250 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:09:48.397641 [debug] [MainThread]: On master: ROLLBACK
[0m16:09:48.398004 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m16:09:48.398355 [debug] [MainThread]: On master: Close
[0m16:09:48.398738 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef276d-c51d-1e67-afb6-ee1a811c1b9a) - Closing connection
[0m16:09:48.484855 [debug] [MainThread]: Connection 'model.my_dbt.dbt_model' was properly closed.
[0m16:09:48.486159 [debug] [MainThread]: On model.my_dbt.dbt_model: ROLLBACK
[0m16:09:48.486754 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m16:09:48.487169 [debug] [MainThread]: On model.my_dbt.dbt_model: Close
[0m16:09:48.487608 [debug] [MainThread]: Databricks adapter: Connection(session-id=01ef276d-c3b4-1f69-a538-e3ad1ecbacc4) - Closing connection
[0m16:09:48.578763 [info ] [MainThread]: 
[0m16:09:48.579946 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.85 seconds (2.85s).
[0m16:09:48.581234 [debug] [MainThread]: Command end result
[0m16:09:48.616010 [info ] [MainThread]: 
[0m16:09:48.616493 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:09:48.616737 [info ] [MainThread]: 
[0m16:09:48.616973 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m16:09:48.619543 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.5447803, "process_user_time": 5.048151, "process_kernel_time": 0.4275, "process_mem_max_rss": "221003776", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m16:09:48.620118 [debug] [MainThread]: Command `dbt run` succeeded at 16:09:48.620034 after 5.55 seconds
[0m16:09:48.620412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11131dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x151828800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x151837830>]}
[0m16:09:48.620673 [debug] [MainThread]: Flushing usage events
